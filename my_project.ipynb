{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42d71b5-2572-4d35-8576-a420e5a95235",
   "metadata": {},
   "source": [
    "This notebooks uses the following dataset <br>\n",
    "https://archive.ics.uci.edu/ml/datasets/Motion+Capture+Hand+Postures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5135214-99c1-4a37-a8bd-f599f715d139",
   "metadata": {},
   "source": [
    "# 1. Analysis of the Problem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70eef1-e2d1-4b29-8546-bb140730fdc1",
   "metadata": {},
   "source": [
    "## Understand the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b0709",
   "metadata": {},
   "source": [
    "working hypothesis\n",
    "think about model architecture\n",
    "loss function\n",
    "and loss criteria\n",
    "\n",
    "select a measure of success\n",
    "    Detect all classes/types of hand gestures with a high accuracy\n",
    "    Classification Problem\n",
    "    Check whether class-imbalanced problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed71874",
   "metadata": {},
   "source": [
    "Dataset with class of the hand gesture/'Class' (our target value) the person which performed the hand gesture ('User') and a \n",
    "feature vector that consists 11 subvectors. Each subvector contains X, Y and Z coordinates. Those coordinates belong to one of the detected markes on the hand glove the user is wearing\n",
    "\n",
    "* motion capture camera records 12 users performing 5 hand postures with markers attached to a left-handed glove\n",
    "* rigid pattern of markers on the back of the glove -> establish local coordinate system for the hand\n",
    "* 11 markers were attached to the thumb and fingers of the glove\n",
    "* there is no a priori correspondence between the markers of two given records\n",
    "* due to the resolution of the capture volume and self-occlusion due to the orientation and configuration of the hand and fingers, many records have missing markers.\n",
    "    -> the number of visible markers in a record varied considerably.\n",
    "\n",
    "\n",
    "The Problem:\n",
    "We cannot easily apply traditional approaches because of two properties of point clouds:\n",
    "* unordered collection (Point 1 with X,Y and Z coordinates could refer to the thh )\n",
    "* the size of the point cloud varies (due to occlusion, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c869c7",
   "metadata": {},
   "source": [
    "## Useful Information from the authors/paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0019a",
   "metadata": {},
   "source": [
    "Class label:<br>\n",
    "1=Fist(with thumb out), 2=Stop(hand flat), 3=Point1(point with pointer finger), 4=Point2(point with pointer and middle fingers), 5=Grab(fingers curled as if to grab)\n",
    "\n",
    "\n",
    "Preprocessing:<br>\n",
    "all markers were transformed to the local coordinate system of the record containing them.\n",
    "\n",
    "Reduce number of records:<br>\n",
    "each transformed marker with a norm greater than 200 millimeters was pruned. \n",
    "records that contained fewer than 3 markers was removed. \n",
    "the data has at most 12 markers per record and at least 3\n",
    "\n",
    "Be careful:<br>\n",
    "It is likely that for a given record and user there exists a near duplicate record originating from the same user.\n",
    "-> evaluate on leave-one-user-out basis wherein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effceef9",
   "metadata": {},
   "source": [
    "## Ideas I want to try out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4c635",
   "metadata": {},
   "source": [
    "\n",
    "**My goal**\n",
    "\n",
    "* able to predict which gesture a person is performing\n",
    "\n",
    "* achieve a high accuracy\n",
    "\n",
    "**My idea/approach**\n",
    "\n",
    "* 1.approach: extract features that are meaningful for a given data point, train conventional models\n",
    "\n",
    "* 2.approach: use models that are adapted to point clouds and have been developed specifically for this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff76df",
   "metadata": {},
   "source": [
    "# 2. Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621bcfc",
   "metadata": {},
   "source": [
    "Check for missing values, NaN values or features,\n",
    "uniqueness of the data (is it as it was expected to be)\n",
    "understand the variations in the data (statistical tools)\n",
    "outliers?\n",
    "Is it possible to combine features?\n",
    "Do you have unnecessary features? (a column which gives no information – for instance name\n",
    "column– or a feature you consider unrelated to the problem)\n",
    "Check the correlation matrix. It will tell you how much the features are related. You may say,\n",
    "for instance, there is a great potential to reduce number of dimensions.\n",
    "scale data (for example, in the [-1, 1] range)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e1faa-b515-472d-8b78-a5489e1d1003",
   "metadata": {},
   "source": [
    "## Preparing the enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbe7a7-59b4-4e40-badd-440f2348011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reload_ext autoreload\n",
    "#%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 60\n",
    "import time\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner\n",
    "from tensorflow.keras import layers\n",
    "from typing import Tuple, Optional, Callable\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# My custom functions\n",
    "from scripts import analyze_helper, visualisation\n",
    "\n",
    "# Utility functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, precision_recall_curve, average_precision_score, recall_score, f1_score, accuracy_score, precision_score\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from os.path import dirname, abspath, join\n",
    "from tqdm.keras import TqdmCallback\n",
    "from random import shuffle\n",
    "\n",
    "# Models we want to use\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae7bb3",
   "metadata": {},
   "source": [
    "## Write utility functions I want to use multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm(y_true, y_pred):\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    class_labels = ['Fist', 'Stop', 'Point1', 'Point2', 'Grab']\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred, labels=[1, 2, 3, 4, 5])\n",
    "    \n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "    #normalize\n",
    "    cf_matrix = (cf_matrix.T/cf_matrix.sum(axis=1)).T\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten()]\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(5,5)\n",
    "\n",
    "    custom_cmap = sns.light_palette(\"#009682\", as_cmap=True)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap=custom_cmap, xticklabels=class_labels, yticklabels=class_labels, cbar=False)\n",
    "    plt.ylabel('true label')\n",
    "    plt.xlabel('predicted label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report:\n",
    "\n",
    "    report: dict\n",
    "\n",
    "    def __init__(self, model_name:str, model, X_test, y_test, description:list=[]):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.description = description\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.report = self.create_report(model)\n",
    "\n",
    "\n",
    "    def create_report(self, model):\n",
    "\n",
    "        try:\n",
    "            if type(model) == keras.Sequential:\n",
    "                y_score = model.predict(self.X_test)\n",
    "            else:\n",
    "                y_score = model.predict_proba(self.X_test)\n",
    "        except AttributeError:\n",
    "            print('No report possible, because no predict_proba method')\n",
    "            report = None\n",
    "            return\n",
    "        y_score_2 = model.predict(self.X_test)\n",
    "\n",
    "        if type(model) != keras.Sequential:\n",
    "            report = classification_report(self.y_test, y_score_2, output_dict=True)\n",
    "        else:\n",
    "            y_score_2 = to_categorical(np.argmax(y_score_2, axis=1))\n",
    "            report = classification_report(self.y_test, y_score_2, output_dict=True)\n",
    "            #NN report does not have accuracy score -> have a look why\n",
    "            accuracy = accuracy_score(self.y_test, y_score_2)\n",
    "            report['accuracy'] = accuracy\n",
    "\n",
    "        return report\n",
    "    \n",
    "    def get_report_as_df(self, df_to_save_to:pd.DataFrame):\n",
    "        'Get the report as a dataframe'\n",
    "\n",
    "        new_row = {'model': self.model_name,\n",
    "                   'Accuracy': round(self.report[\"accuracy\"],6), \n",
    "                   'Precision': round(self.report[\"macro avg\"][\"precision\"],5),\n",
    "                   'Recall': round(self.report[\"macro avg\"][\"recall\"],6),\n",
    "                   'F1_score': round(self.report[\"macro avg\"][\"f1-score\"],6)} \n",
    "        df_to_save_to = df_to_save_to.append(new_row, ignore_index=True)\n",
    "\n",
    "        return df_to_save_to\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        if self.report is None:\n",
    "            print('No return possbile')\n",
    "            return 'No valid return'\n",
    "\n",
    "        pattern = '''\n",
    "        ***********************REPORT*******************************\n",
    "        Average (macro) precision: {}\n",
    "        Average accuracy: {}\n",
    "        Average (macro) recall: {}\n",
    "        Average (macro) f1-score: {}\n",
    "        Description {}\n",
    "        ************************************************************\n",
    "        '''\n",
    "        return pattern.format(round(self.report[\"macro avg\"][\"precision\"],5), round(self.report[\"accuracy\"],6), round(self.report[\"macro avg\"][\"recall\"],6), round(self.report[\"macro avg\"][\"f1-score\"],6), ', '.join(self.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5843a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_eval_dict_pkl(eval_dict, name):\n",
    "\n",
    "    # Get path to save the history\n",
    "    eval_folder = 'model/single_run/eval'\n",
    "    model_path = join(eval_folder, name)\n",
    "    \n",
    "    with open(model_path, 'wb') as file_pi:\n",
    "        pickle.dump(eval_dict, file_pi)\n",
    "\n",
    "def load_eval_dict_pkl(name) -> dict:\n",
    "\n",
    "    # Get path to save the history\n",
    "    eval_folder = 'model/single_run/eval'\n",
    "    model_path = join(eval_folder, name)\n",
    "\n",
    "    with open(model_path, 'rb') as file_pi:\n",
    "        eval_dict = pickle.load(file_pi)\n",
    "    \n",
    "    return eval_dict\n",
    "\n",
    "def save_to_eval_dict(eval_dict:dict, split_set:str, acc:float, precission:float, recall:float, f1:float):\n",
    "    ''' Save multiple metrics to a dictionary for evaluation '''\n",
    "\n",
    "    if split_set not in ['train', 'test']:\n",
    "        raise ValueError('split_set must be either train or test')\n",
    "    \n",
    "    eval_dict[split_set]['accuracy'].append(acc)\n",
    "    eval_dict[split_set]['precision'].append(precission)\n",
    "    eval_dict[split_set]['recall'].append(recall)\n",
    "    eval_dict[split_set]['f1'].append(f1)\n",
    "\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eeeda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eval_dict_barplot_new(data):\n",
    "\n",
    "    # Extracting data\n",
    "    train_acc = data['train']['accuracy']\n",
    "    train_prec = data['train']['precision']\n",
    "    train_recall = data['train']['recall']\n",
    "    train_f1 = data['train']['f1']\n",
    "    test_acc = data['test']['accuracy']\n",
    "    test_prec = data['test']['precision']\n",
    "    test_recall = data['test']['recall']\n",
    "    test_f1 = data['test']['f1']\n",
    "\n",
    "    # Creating subplots for accuracy and precision\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 5))\n",
    "    bar_width = 0.2\n",
    "\n",
    "    # Plot for accuracy\n",
    "    axs[0][0].bar([i+bar_width/2 for i in range(len(train_acc))], train_acc, width=bar_width, color='b', label='Train Accuracy')\n",
    "    axs[0][0].bar([i-bar_width/2 for i in range(len(test_acc))], test_acc, width=bar_width, color='r', label='Test Accuracy')\n",
    "    axs[0][0].set_xticks(range(len(train_acc)))\n",
    "    axs[0][0].set_xticklabels([f'CV{i}' for i in range(len(train_acc))])\n",
    "    axs[0][0].set_ylabel('Accuracy')\n",
    "    axs[0][0].set_title('Accuracy')\n",
    "    axs[0][0].legend()\n",
    "\n",
    "    # Plot for precision\n",
    "    axs[0][1].bar([i+bar_width/2 for i in range(len(train_prec))], train_prec, width=bar_width, color='b', label='Train Precision')\n",
    "    axs[0][1].bar([i-bar_width/2 for i in range(len(test_prec))], test_prec, width=bar_width, color='r', label='Test Precision')\n",
    "    axs[0][1].set_xticks(range(len(train_acc)))\n",
    "    axs[0][1].set_xticklabels([f'CV{i}' for i in range(len(train_acc))])\n",
    "    axs[0][1].set_ylabel('Precision')\n",
    "    axs[0][1].set_title('Precision')\n",
    "    axs[0][1].legend()\n",
    "\n",
    "    # Plot for recall\n",
    "    axs[1][0].bar([i+bar_width/2 for i in range(len(train_recall))], train_recall, width=bar_width, color='b', label='Train Recall')\n",
    "    axs[1][0].bar([i-bar_width/2 for i in range(len(test_recall))], test_recall, width=bar_width, color='r', label='Test Recall')\n",
    "    axs[1][0].set_xticks(range(len(train_recall)))\n",
    "    axs[1][0].set_xticklabels([f'CV{i}' for i in range(len(train_recall))])\n",
    "    axs[1][0].set_ylabel('Recall')\n",
    "    axs[1][0].set_title('Recall')\n",
    "    axs[1][0].legend()\n",
    "\n",
    "    # Plot for f1_score\n",
    "    axs[1][1].bar([i+bar_width/2 for i in range(len(train_f1))], train_f1, width=bar_width, color='b', label='Train F1-Score')\n",
    "    axs[1][1].bar([i-bar_width/2 for i in range(len(test_f1))], test_f1, width=bar_width, color='r', label='Test F1-Score')\n",
    "    axs[1][1].set_xticks(range(len(train_f1)))\n",
    "    axs[1][1].set_xticklabels([f'CV{i}' for i in range(len(train_f1))])\n",
    "    axs[1][1].set_ylabel('F1 Score')\n",
    "    axs[1][1].set_title('F1 Score')\n",
    "    axs[1][1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dbaf5d-96bf-4e9c-baf4-905ed859f7c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07e663-c32d-4b98-9088-57c49d18b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_raw = os.path.join('data', 'Postures.csv')\n",
    "df_raw = pd.read_csv(file_path_raw, sep=',', na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b72cb9",
   "metadata": {},
   "source": [
    "## Understand the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8e0c7",
   "metadata": {},
   "source": [
    "### Choose a metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f530b1",
   "metadata": {},
   "source": [
    "To choose a metric we have to check whether the classes are balenced/unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc896a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df_raw['Class'].value_counts(sort=False)\n",
    "class_counts.plot(kind='bar', title='Gestures Class Distibution')\n",
    "plt.xlim(0.5, df_raw['Class'].max()+0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b007c1",
   "metadata": {},
   "source": [
    "To jugde the model perfomance we will choose a mixture of multiple metrics:\n",
    "* Confusion Matrix\n",
    "* Accuracy (we have balanced classes!)\n",
    "* Recall (made TP predictions divided by possible TP predictions)\n",
    "* precission-recall plot\n",
    "* F1-Score (harmonic mean between recall and precision, combines the two metrics into one value)\n",
    "\n",
    "TODO \n",
    "Maybe Later\n",
    "* ROC AUC (Receiver Operator Characteristic — Area Under the Curve, we want a high TPR with a low FPR)\n",
    "Note: we will use the One vs Rest strategy for ROC AUC (because it is usally a metric for binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe4d214",
   "metadata": {},
   "source": [
    "Write utility function to use the ROC AUC for multiclass classficiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7bb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_multiclass(model, X_test, y_test):\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    y_score = model.predict_proba(X_test)\n",
    "    y_score_2 = model.predict(X_test)\n",
    "    \n",
    "    #print('Amount and Distribution of Test Data: \\n', y_test.value_counts())\n",
    "    y_bin = pp.label_binarize(y_test, classes=model.classes_)\n",
    "\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    classes = model.classes_\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_bin[:, i], y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(y_bin[:, i], y_score[:, i])\n",
    "        #print('\\n average precision: ', classes[i], ': ', average_precision[i])\n",
    "        try:\n",
    "            plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(classes[i]))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    \n",
    "    plt.xlabel(\"recall\")\n",
    "    plt.ylabel(\"precision\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"precision vs. recall curve\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b640a001-a477-4f13-a4ec-c9f9306bf727",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1b443-1126-4ad6-9236-4d325e12dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29bafb-29a4-4f25-9d9b-86cfba219b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which columns have missing values\n",
    "print(f\"Missing values in: {analyze_helper.check_for_missing_vals(df_raw)}\")\n",
    "# Compute missing ratio, hide columns with no missing values (0.0%)\n",
    "analyze_helper.compute_missing_ratio(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc34347",
   "metadata": {},
   "source": [
    "Hint 1 for preprocessing:\n",
    "drop the coordinates (X,Y,Z) for point 10 and 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93bd9c-0bea-4be4-96f7-3d3c3b250437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3cf151-48ba-421c-8d3a-0d3f7673004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head(5)\n",
    "df_raw.drop([0], inplace=True)\n",
    "df_raw.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Instances  : ', df_raw.shape[0])\n",
    "print('Number of Attributes : ', df_raw.shape[1])\n",
    "print('Number of target classes   : ', df_raw['Class'].nunique())\n",
    "print('Number of users   : ', df_raw['User'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c73d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['User'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7cb979",
   "metadata": {},
   "source": [
    "The description says the data set contains 12 User. No information provided (why are 14 user in the data?).\n",
    "Hint for us to drop User 4 and 7 ?\n",
    "They both have signifiantly less data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848511d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_group = df_raw.groupby(['User'], sort=False)\n",
    "user_group.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfdf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60989e0-5d3b-4ad2-95c6-1fbdaa290726",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084054c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltHand(handPoints):\n",
    "    plt.close('all')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    \n",
    "    for i in range(11):\n",
    "        pntx = f'X{i}'\n",
    "        pnty = f'Y{i}'\n",
    "        pntz = f'Z{i}'\n",
    "        \n",
    "        if(handPoints[pntx].values[0] == 0 or\n",
    "            handPoints[pnty].values[0] == 0 or\n",
    "            handPoints[pntz].values[0] == 0):\n",
    "            n = 0;\n",
    "        else:\n",
    "            xlocation = handPoints[pntx]\n",
    "            ylocation = handPoints[pnty]\n",
    "            zlocation = handPoints[pntz]\n",
    "            ax.scatter(xlocation, ylocation, zlocation, marker='v')\n",
    "    \n",
    "    crntClass = handPoints['Class'].values[0]\n",
    "    if (crntClass == 1):\n",
    "        title = 'Fist + Thumb out'\n",
    "    if(crntClass == 2):\n",
    "        title = 'Stop/Flat hand'\n",
    "    if (crntClass == 3):\n",
    "        title = 'Point with pointer finger'\n",
    "    if (crntClass == 4):\n",
    "        title = 'Point with pointer + middle finger'\n",
    "    if (crntClass == 5):\n",
    "        title = 'Grab'\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58feb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterPlot2D(x_DF, y_DF, labels:list):\n",
    "    #df = pd.DataFrame(data=x_DF.iloc[:,0:2], index=x_DF.index)\n",
    "    df = pd.DataFrame(data=x_DF, index=x_DF.index)\n",
    "    df = pd.concat((df,y_DF), axis=1, join=\"inner\")\n",
    "    df.columns = [\"First Dimension\", \"Second Dimension\", \"Class\"]\n",
    "    sns.lmplot(x=\"First Dimension\",y=\"Second Dimension\", hue=\"Class\", data=df, fit_reg=False)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Visualization of the data segragation using \")\n",
    "\n",
    "def scatterPlot3D(x_DF, y_DF, labels:dict):\n",
    "    df = pd.DataFrame(data=x_DF.iloc[:,0:3], index=x_DF.index)\n",
    "    df = pd.concat((df,y_DF), axis=1, join=\"inner\")\n",
    "    fig = px.scatter_3d(df, x=df.columns[0], y=df.columns[1], z=df.columns[2],\\\n",
    "                          color='Class', symbol='Class', opacity=0.7, \\\n",
    "                          color_continuous_scale=px.colors.sequential.Viridis, width = 600, height = 500,\n",
    "                       labels=labels) \n",
    "\n",
    "    title = \"Visualization of the data segragation using \"\n",
    "    fig.update_layout(title_text=title, showlegend = True, hovermode = False)\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "    fig.update_layout(legend=dict(yanchor=\"top\",y=0.99,xanchor=\"left\",x=0.01))\n",
    "\n",
    "    fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68869c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a random hand gesture from the dataset to get a an idea of the data\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "for _ in range(4):\n",
    "    rand_dp = np.random.randint(df_raw.shape[0], size=1)[0]\n",
    "    pltHand(df_raw[rand_dp:rand_dp+1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df: pd.DataFrame):\n",
    "\n",
    "    correlationMatrix = pd.DataFrame(df_raw).corr() \n",
    "    f = plt.figure(figsize=(12, 6))\n",
    "    plt.matshow(correlationMatrix, fignum=f.number)\n",
    "    plt.xticks(range(df_raw.shape[1]), df_raw.columns, fontsize=14, rotation=75)\n",
    "    plt.yticks(range(df_raw.shape[1]), df_raw.columns, fontsize=14)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89d258-53ae-43fb-8b22-2c09e406af70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataframe we want to store x_mean, y_mean and z_mean in\n",
    "df_xyz = pd.DataFrame()\n",
    "\n",
    "# We dont want to change the original data set\n",
    "df_raw_dummy = df_raw.copy(deep=True)\n",
    "\n",
    "# Save the user and class column\n",
    "df_user = df_raw_dummy.pop('User')\n",
    "df_class = df_raw_dummy.pop('Class')\n",
    "\n",
    "# We replace all zeros with NaN, so the mean calculatiion ignores occluded data points\n",
    "df_raw_dummy = df_raw_dummy.replace(0, np.NaN)\n",
    "\n",
    "# Extract the X, Y and Z columns\n",
    "df_x_vals = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith('X')]]\n",
    "df_y_vals = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith('Y')]]\n",
    "df_z_vals = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith('Z')]]\n",
    "\n",
    "# Extract the mean of the X, Y and Z columns\n",
    "for coordinate in ['X', 'Y', 'Z']:\n",
    "    coordinate_cols = df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith(coordinate)]\n",
    "    df_xyz[f'{coordinate}_mean'] = df_raw_dummy[coordinate_cols].mean(axis=1)\n",
    "    df_xyz[f'{coordinate}_min'] = df_raw_dummy[coordinate_cols].min(axis=1)\n",
    "    df_xyz[f'{coordinate}_max'] = df_raw_dummy[coordinate_cols].max(axis=1)\n",
    "\n",
    "# Add user and class label\n",
    "df_xyz['User'] = df_user\n",
    "df_xyz['Class'] = df_class\n",
    "# Change NaN back to 0 values\n",
    "df_raw_dummy = df_raw_dummy.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c80235-6a45-4fd3-92d2-f94d845e3353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f789c671-17a3-4ed5-a741-cbc26b6173d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_xyz = df_xyz.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749aa36-6fd1-4ccf-90ab-771427fb022b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85188bca-0270-4873-9731-2b209e17816c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels = ['Fist', 'Stop', 'Point1', 'Point2', 'Grab']\n",
    "df_xyz = df_xyz.reset_index(drop=True)\n",
    "scatterPlot3D(df_xyz[['X_mean', 'Y_mean', 'Z_mean']], df_class, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71ae2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf85385",
   "metadata": {},
   "source": [
    "Principal Component Analysis\n",
    "* reduce the dimensionality of the data.\n",
    "* This makes the data faster and easier to process.\n",
    "* when dimensionality is reduced in 2D or 3D, data of higher dimensions can be visualized in a human-readable graph.<br>\n",
    "\n",
    "Best case: the 2D and 3D graph can directly give an understanding of how well the data can be classified. If there are already well visible clusters in the 2D graph, it is reasonable to conclude that a classification algorithm can easily detect this pattern<br>\n",
    "\n",
    "Lets see how our data looks like after dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ec922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute PCA and plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed6f95",
   "metadata": {},
   "source": [
    "First we right some functions to plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c8780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "df_pca = df_raw.copy()\n",
    "df_pca.drop(['User', 'Class'], inplace=True, axis=1)\n",
    "pca.fit(df_pca)\n",
    "features_pca = pd.DataFrame(pca.transform(df_pca))\n",
    "classes = df_raw[['Class']].copy()\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"First 2: \", np.round(sum(pca.explained_variance_ratio_[0:1])*100,2),\"%\")\n",
    "print(\"First 3: \", np.round(sum(pca.explained_variance_ratio_[0:2])*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c94803-6cd2-4145-bb7c-3053b1498a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c016c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels = ['Fist', 'Stop', 'Point1', 'Point2', 'Grab']\n",
    "scatterPlot2D(features_pca.iloc[:,0:2], classes, class_labels)\n",
    "scatterPlot3D(features_pca, classes, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967442a-81b4-4159-b2fa-ff2e2d589415",
   "metadata": {},
   "source": [
    "Results:<br>\n",
    "In these two representations we can clearly see that clusters of classes are partially formed. However, these overlap, i.e. the interclass distance is relatively small.\n",
    "In addition, we see that class 2 forms a second, smaller cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28aba7",
   "metadata": {},
   "source": [
    "Now we can also have a look how much variance of the data each pca component describes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04117d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_explained_variance(pca:PCA):\n",
    "\n",
    "    pca_variance_ratio = pca.explained_variance_ratio_\n",
    "    cum_sum_eigenvalues = np.cumsum(pca_variance_ratio)\n",
    "    print(f'Total explained variance ratio:', sum(pca_variance_ratio))\n",
    "    \n",
    "    plt.bar(range(0,len(pca_variance_ratio)), pca_variance_ratio, alpha=0.5, align='center', label='Individual explained variance')\n",
    "    plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance', color='r')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal component index')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8cddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explained_variance(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df829be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO results of explained ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e371b-a8fb-4546-a596-19e5c60a0d83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db67d8ed",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows of user 4 and 7\n",
    "# Because they have significantly less data points\n",
    "df_raw = df_raw[df_raw['User'] != 4]\n",
    "df_raw = df_raw[df_raw['User'] != 7]\n",
    "df_raw.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba31201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop coordinates of point 10 and 11\n",
    "# More than 90% of the data is missing\n",
    "# Search for \"Hint 1\" for further information\n",
    "df_raw.drop(['X10', 'Y10', 'Z10', 'X11', 'Y11', 'Z11'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e5717a-e460-4985-8ffd-e90171aac4d2",
   "metadata": {},
   "source": [
    "### Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d1899",
   "metadata": {},
   "source": [
    "#### a. Extract features (min, max, mean, etc.) - df_aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e93f605-60b1-4ba3-9571-03afa0a4178a",
   "metadata": {},
   "source": [
    "Ideas for new features: (inspired from paper)<br>\n",
    "* number of markers\n",
    "* mean (per coordinate)\n",
    "* Eigenvalues and vectors of the points covariance matrix\n",
    "https://math.stackexchange.com/questions/2842830/why-does-the-eigen-decomposition-of-the-covariance-matrix-of-a-point-cloud-give\n",
    "* dimensions of the axis-aligned minimum bounding box centered on the mean\n",
    "\n",
    "Keep in mind that each feature has to aggregate the points in such a way that the result is order invariant!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data set we want to fill step by step\n",
    "df_aggregate= pd.DataFrame()\n",
    "# We dont want to change the original data set\n",
    "df_raw_dummy = df_raw.copy(deep=True)\n",
    "\n",
    "# Save the user and class column\n",
    "df_user = df_raw_dummy.pop('User')\n",
    "df_class = df_raw_dummy.pop('Class')\n",
    "\n",
    "# We replace all zeros with NaN, so the mean calculatiion ignores occluded data points\n",
    "df_raw_dummy = df_raw_dummy.replace(0, np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6aa07a-8418-42ce-b560-099ecece123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the X, Y and Z columns\n",
    "df_x = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith('X')]]\n",
    "df_y = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith('Y')]]\n",
    "df_z = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith('Z')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the mean, min, max etc. of the X, Y and Z columns\n",
    "for coordinate in ['X', 'Y', 'Z']:\n",
    "    coordinate_cols = df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith(coordinate)]\n",
    "    df_aggregate[f'{coordinate}_mean'] = df_raw_dummy[coordinate_cols].mean(axis=1)\n",
    "    df_aggregate[f'{coordinate}_min'] = df_raw_dummy[coordinate_cols].min(axis=1)\n",
    "    df_aggregate[f'{coordinate}_max'] = df_raw_dummy[coordinate_cols].max(axis=1)\n",
    "\n",
    "# Change NaN back to 0 values\n",
    "df_raw_dummy = df_raw_dummy.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b954b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the number of visible points (not occluded)\n",
    "df_aggregate['n_points'] = (df_raw_dummy.astype(bool).sum(axis=1))/3\n",
    "df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf820fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0cdac",
   "metadata": {},
   "source": [
    "My idea:<br>\n",
    "find the orientation of a given cluster<br>\n",
    "(https://math.stackexchange.com/questions/2842830/why-does-the-eigen-decomposition-of-the-covariance-matrix-of-a-point-cloud-give)\n",
    "\n",
    "1. Rearange the dataset (1 point per row with X, Y, Z value)\n",
    "-> All points per row will be saved in a batch as new sub dataframe\n",
    "2. Compute the covariance matrix for each sub dataframe\n",
    "3. Calculate the Eigenvalues and Eigenvectors of the covariance matrix\n",
    "4. Concat created features to the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1ea52",
   "metadata": {},
   "source": [
    "DISCLAIMER: <br>\n",
    "The following function can take up to 1 min!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c5a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume you have a DataFrame called 'df' with the columns ['X0', 'Y0', 'Z0', 'X1', 'Y1', 'Z1', 'X2', 'Y2', 'Z2']\n",
    "# Reorganize the dataframe to have each row as a batch of data\n",
    "# 'X0', 'Y0', 'Z0',\n",
    "# 'X1', 'Y1', 'Z1',\n",
    "# 'X2', 'Y2', 'Z2'\n",
    "\n",
    "# Create an empty list to store the batches of data\n",
    "batches = []\n",
    "\n",
    "# Iterate over the DataFrame and extract the batches of data\n",
    "for row in range(0, df_raw_dummy.shape[0]):\n",
    "\n",
    "    col_batch = []\n",
    "    # Extract a batch of data for the current row\n",
    "    for col in range(0, df_raw_dummy.shape[1], 3):\n",
    "        batch = df_raw_dummy.iloc[row, col:col+3]\n",
    "        # Rename the columns\n",
    "        batch.index = ['X', 'Y', 'Z']\n",
    "        #print(f'batch: {batch}')\n",
    "        col_batch.append(batch)\n",
    "    # Append the batch to the list\n",
    "    batches.append(col_batch)\n",
    "\n",
    "# Concatenate the batches of data under each other\n",
    "concat_batches = []\n",
    "for batch in batches:\n",
    "    concat_batch = pd.concat(batch, axis=1).transpose()\n",
    "    concat_batches.append(concat_batch)\n",
    "    # Remove rows with all zeros\n",
    "    concat_batch = concat_batch[(concat_batch.T != 0).any()]\n",
    "\n",
    "# Create a dictionary with the eigenvalues and eigenvectors as values\n",
    "eigen_dict = {'eigenvec_1_1': [],\n",
    "                'eigenvec_1_2': [],\n",
    "                'eigenvec_1_3': [],\n",
    "                'eigenvec_2_1': [],\n",
    "                'eigenvec_2_2': [],\n",
    "                'eigenvec_2_3': [],\n",
    "                'eigenvec_3_1': [],\n",
    "                'eigenvec_3_2': [],\n",
    "                'eigenvec_3_3': [],\n",
    "              'eigenval_1': [],\n",
    "              'eigenval_2': [],\n",
    "              'eigenval_3': []}\n",
    "\n",
    "# Create the DataFrame\n",
    "eigen_df = pd.DataFrame(eigen_dict)\n",
    "\n",
    "# Compute the covariance matrix for each batch\n",
    "for concat_batch in concat_batches:\n",
    "    # Compute the covariance matrix\n",
    "    cov_matrix = np.cov(concat_batch, rowvar=False)\n",
    "    # Compute the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "    # Add the eigenvalues and eigenvectors to the DataFrame\n",
    "    # Store eigenvector 1\n",
    "    eigen_dict['eigenvec_1_1'].append(eigenvectors[0, 0])\n",
    "    eigen_dict['eigenvec_1_2'].append(eigenvectors[1, 0])\n",
    "    eigen_dict['eigenvec_1_3'].append(eigenvectors[2, 0])\n",
    "    # Store eigenvector 2\n",
    "    eigen_dict['eigenvec_2_1'].append(eigenvectors[0, 1])\n",
    "    eigen_dict['eigenvec_2_2'].append(eigenvectors[1, 1])\n",
    "    eigen_dict['eigenvec_2_3'].append(eigenvectors[2, 1])\n",
    "    # Store eigenvector 3\n",
    "    eigen_dict['eigenvec_3_1'].append(eigenvectors[0, 2])\n",
    "    eigen_dict['eigenvec_3_2'].append(eigenvectors[1, 2])\n",
    "    eigen_dict['eigenvec_3_3'].append(eigenvectors[2, 2])\n",
    "    # Store eigenvalues\n",
    "    eigen_dict['eigenval_1'].append(eigenvalues[0])\n",
    "    eigen_dict['eigenval_2'].append(eigenvalues[1])\n",
    "    eigen_dict['eigenval_3'].append(eigenvalues[2])\n",
    "\n",
    "# Finally add generated features to the DataFrame\n",
    "df_aggregate = pd.concat([df_aggregate, pd.DataFrame(eigen_dict)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485aefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user and class information to the new data set after the feature extraction\n",
    "df_aggregate['User'] = df_user\n",
    "df_aggregate['Class'] = df_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef523fc",
   "metadata": {},
   "source": [
    "**Evaluation Strategy**:<br>\n",
    "We will use a k-Fold cross-validation to evaluate our model <br>\n",
    "We randomly choose 2 User for the test set <br>\n",
    "Then we remove the users from the selectable list so that each user is in the test data set at most once over all k runs <br>\n",
    "For the next split we again choose 2 random User, and so on<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_train_test_user(df:pd.DataFrame, user_list:list, num_user_test:int=2):\n",
    "    '''This function returns the indices for the training and test set.\n",
    "    The function randomly selects two users for the test set and the remaining\n",
    "    users for the training set.\n",
    "    \n",
    "    return: train_indices, test_indices'''\n",
    "\n",
    "    # Create a list of indices for the training and test set\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Generate 2 random numbers between 0 and 14\n",
    "    test_user_1, test_user_2, test_user_3 = random.sample(user_list, num_user_test)\n",
    "    print(f'User picked for test set: {test_user_1}, {test_user_2}')\n",
    "    \n",
    "\n",
    "    # Iterate over the users\n",
    "    for user in user_list:\n",
    "        # Get the indices for the current user\n",
    "        indices = df[df['User'] == user].index\n",
    "        # Append the indices to the list\n",
    "        if user == test_user_1 or user == test_user_2 or user == test_user_3:\n",
    "            test_indices.extend(indices)\n",
    "        else:\n",
    "            train_indices.extend(indices)\n",
    "    \n",
    "    # Remove the test users from the user list so they cannot be selected again\n",
    "    user_list = [x for x in user_list if x != test_user_1 and x != test_user_2]\n",
    "\n",
    "    return train_indices, test_indices, user_list\n",
    "\n",
    "def custom_cv_approach(df:pd.DataFrame, user_list:list, num_user_test:int=2):\n",
    "    '''\n",
    "    each user is iteratively left out from training and used as a test set. \n",
    "    We then tests the generalization of the algorithm to new users. \n",
    "    A 'User' attribute is provided to accomodate this strategy. \n",
    "    '''\n",
    "    def cv_ratio(y_test, df):\n",
    "        print(f'Ratio of test set: {len(y_test)/len(df)}')\n",
    "    \n",
    "    # Get the indices for the training and test set\n",
    "    train_indices, test_indices, user_list = get_train_test_user(df, user_list, num_user_test)\n",
    "    # Create the training and test set\n",
    "    X_train = df.iloc[train_indices, :]\n",
    "    X_train = X_train.sample(frac=1, random_state=2023).reset_index(drop=True) #Shuffle\n",
    "    y_train = X_train.pop('Class')\n",
    "    X_train.pop('User')\n",
    "    X_test = df.iloc[test_indices, :]\n",
    "    X_test = X_test.sample(frac=1, random_state=2023).reset_index(drop=True) #Shuffle \n",
    "    y_test = X_test.pop('Class')\n",
    "    X_test.pop('User')\n",
    "\n",
    "    # Print the ratio of the test set\n",
    "    cv_ratio(y_test, df)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, user_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_group = df_aggregate.groupby(['User'], sort=False)\n",
    "user_group.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d51c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add augmentation to the data set.\n",
    "# e.g. add Jitter or Shuffle data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c27403-ded5-4ba2-911b-778112ab4445",
   "metadata": {},
   "source": [
    "#### b. Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bccb4fe",
   "metadata": {},
   "source": [
    "Of course we will also keep the raw data set and a data set with extracted features. In a later step we want to compare different data sets and their perfomance.<br>\n",
    "Here we will extract one data set that contains pca components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b0027e-6c38-4e17-a19d-43397b492d48",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will choose n_components because their explained variance ratio is above 0.95\n",
    "n_components = 25\n",
    "pca = PCA(n_components=n_components)\n",
    "df_pca = df_raw.copy()\n",
    "\n",
    "# Drop the user and class information, they are not needed for the PCA\n",
    "df_user = df_pca.pop('User')\n",
    "df_class = df_pca.pop('Class')\n",
    "\n",
    "pca.fit(df_pca)\n",
    "df_pca_features = pd.DataFrame(pca.transform(df_pca))\n",
    "\n",
    "# Now add the user and class information again\n",
    "df_pca_features['User'] = df_user\n",
    "df_pca_features['Class'] = df_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd5b4a",
   "metadata": {},
   "source": [
    "#### c.I Split data - Wrong way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3b3ea",
   "metadata": {},
   "source": [
    "#### Demonstration data set (WRONG WAY) - mixed user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9487229",
   "metadata": {},
   "source": [
    "******************************************************\n",
    "DEMONSTRATION: this shows how NOT to do it:<br>\n",
    "Splitting the naive way (similar data points will be in both sets)\n",
    "******************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7940eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c585d02-1dc7-41bc-a8fe-e47d0d70e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into train and test set\n",
    "X_train_mixed, X_test_mixed, y_train_mixed, y_test_mixed = train_test_split(df_raw, df_raw['Class'], test_size=0.25)\n",
    "user_group = df_raw.groupby(['User'], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb68af6",
   "metadata": {},
   "source": [
    "We normalize the data using a Min-Max-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data with MinMaxScaler\n",
    "\n",
    "# Create the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the training data\n",
    "scaler.fit(X_train_mixed)\n",
    "\n",
    "# Transform the training and test data\n",
    "X_train_mixed = scaler.transform(X_train_mixed)\n",
    "X_test_mixed = scaler.transform(X_test_mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d550bc",
   "metadata": {},
   "source": [
    "#### c.II Split data properly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941cf30",
   "metadata": {},
   "source": [
    "We now have a CV loop:\n",
    "I split the data in the same loop, where I train the model for a specific k-fold <br>\n",
    "Therefore I dont split the data beforehand in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab41a1-9b02-4916-9089-38a43d021429",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Testing Phase I: Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c4ee0",
   "metadata": {},
   "source": [
    "After we have trained all the models, we want to compare the model performance using selected metrics. Therefore we need to save the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b972908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca0de32",
   "metadata": {},
   "source": [
    "First, we write a training function to have a common interface for all conventional machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df:pd.DataFrame, model_func: Callable, scaler_choice:str, kwargs_dict:dict):\n",
    "    '''This function provides a common interface to train the classic ml models.\n",
    "    In a loop we iterate over different train and test sets and train the model.\n",
    "    We leave out k users from the data set and use them as test set.\n",
    "    '''\n",
    "\n",
    "    # Create a list of users\n",
    "    user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "    # Number of users to be used for the test set\n",
    "    num_user_test = 3\n",
    "    num_of_iterations = 4\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    X_test_best = None\n",
    "    y_test_best = None\n",
    "\n",
    "    # Save evaluation metrics in a dictionary\n",
    "    eval_dict = {'train': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []},\n",
    "                    'test': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []}}\n",
    "\n",
    "    for i in range(num_of_iterations):\n",
    "\n",
    "        print('*'*50)\n",
    "        print(f'CV Run: {i}')\n",
    "\n",
    "        model = model_func(**kwargs_dict)\n",
    "\n",
    "        # Split the data\n",
    "        X_train, y_train, X_test, y_test, user_list = custom_cv_approach(df, user_list, num_user_test=num_user_test)\n",
    "\n",
    "        if scaler_choice == 'normalize':\n",
    "            # Normalize the data\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        elif scaler_choice == 'standard':\n",
    "            # Standard Scale the data\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        else:\n",
    "            print('No scaling applied')\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        model_acc = model.score(X_test, y_test)\n",
    "        \n",
    "        # Print the results\n",
    "        print('Train accuracy: ', model.score(X_train, y_train))\n",
    "        print('(CV-) Test accuracy: ', model_acc)\n",
    "\n",
    "        # Save the results\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        train_acc = accuracy_score(y_train, y_pred_train)\n",
    "        train_precision = precision_score(y_train, y_pred_train, average='macro')\n",
    "        train_recall = recall_score(y_train, y_pred_train, average='macro')\n",
    "        f1_score_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'train', train_acc, train_precision, train_recall, f1_score_train)\n",
    "\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        val_acc = accuracy_score(y_test, y_pred_test)\n",
    "        val_precision = precision_score(y_test, y_pred_test, average='macro')\n",
    "        val_recall = recall_score(y_test, y_pred_test, average='macro')\n",
    "        f1_score_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'test', val_acc, val_precision, val_recall, f1_score_test)\n",
    "\n",
    "        # Save best model\n",
    "        if model_acc > best_acc:\n",
    "            best_model = model\n",
    "            best_acc = model_acc\n",
    "            X_test_best = X_test\n",
    "            y_test_best = y_test\n",
    "\n",
    "    return best_model, X_test_best, y_test_best, eval_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9990a7-bfa6-4a4f-a796-6ace870559f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grid_search(df:pd.DataFrame, model_func: Callable, scaler_choice:str, cv_k:int, kwargs_dict:dict):\n",
    "    '''\n",
    "    Grid search function for conventional ML models.\n",
    "    similiar to the train_model function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing the data, either raw or aggregated.\n",
    "    model_func : Callable\n",
    "        Function that returns a model object.\n",
    "    scaler_choice : str\n",
    "        Choice of scaler to be used. Either 'normalize' or 'standard'.\n",
    "    cv_k : int\n",
    "        Number of iterations for the cross validation.\n",
    "    '''\n",
    "\n",
    "    # Create a list of users\n",
    "    user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "    # Number of users to be used for the test set\n",
    "    num_user_test = 3\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    best_param = None\n",
    "    X_test_best = None\n",
    "    y_test_best = None\n",
    "\n",
    "    # Save all grid search objects in a list\n",
    "    grid_search_list = []\n",
    "\n",
    "    for i in range(cv_k):\n",
    "\n",
    "        print('*'*50)\n",
    "        print(f'CV Run: {i}')\n",
    "\n",
    "        # Split the data\n",
    "        X_train, y_train, X_test, y_test, user_list = custom_cv_approach(df, user_list, num_user_test=num_user_test)\n",
    "\n",
    "        if scaler_choice == 'normalize':\n",
    "            # Normalize the data\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        elif scaler_choice == 'standard':\n",
    "            # Standard Scale the data\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        else:\n",
    "            print('No scaling applied')\n",
    "\n",
    "        # IMPORTANT: Define own train test split (otherwise GridSearch uses 5-CrossValidation)\n",
    "        X_complete = np.concatenate((X_train, X_test), axis=0)\n",
    "        y_complete = np.concatenate((y_train, y_test), axis=0)\n",
    "        # The indices which have the value -1 will be kept in train.\n",
    "        # The indices which have zero or positive values, will be kept in test\n",
    "        test_fold = np.concatenate([np.full(len(X_train), -1, dtype=np.int8), np.zeros(len(X_test), dtype=np.int8)])\n",
    "        cv_train_test = PredefinedSplit(test_fold)\n",
    "        # Check how many splits will be done, based on test_fold\n",
    "        print('Number of splits: ',cv_train_test.get_n_splits())\n",
    "\n",
    "        # Create grid search object\n",
    "        grid_search = GridSearchCV(cv=cv_train_test, **kwargs_dict)\n",
    "        # Alternativce a Random Search\n",
    "        # rnd_search = RandomizedSearchCV(svm_model, n_jobs=n_jobs, param_distributions=params, n_iter=num_iter, cv=cv_train_test, verbose=3, retrain=False)\n",
    "\n",
    "        # Fit the model\n",
    "        grid_search.fit(X_complete, y_complete)\n",
    "    \n",
    "        grid_search_list.append(grid_search)\n",
    "\n",
    "        print(f\"Best score: {round(grid_search.best_score_, 3)}\")\n",
    "        print(f\"Best params: {grid_search.best_params_}\")\n",
    "\n",
    "        # Save best model\n",
    "        if grid_search.best_score_ > best_acc:\n",
    "            best_acc = grid_search.best_score_\n",
    "            X_train_best = X_train\n",
    "            y_train_best = y_train\n",
    "            X_test_best = X_test\n",
    "            y_test_best = y_test\n",
    "            best_param = grid_search.best_params_\n",
    "    \n",
    "    # Retrain the best model\n",
    "    # Usually we can use the refit parameter of the search object\n",
    "    # but the would also fit on the test data\n",
    "    model = model_func(**best_param)\n",
    "    model.fit(X_train_best, y_train_best)\n",
    "    \n",
    "    return model, X_test_best, y_test_best, grid_search_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88505742",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b14d2-50f2-439f-88cf-9ace62e40671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#You need to check model descriptions for the hyperparameters. \n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier\n",
    "#-----------------------------------------------------------------\n",
    "# Number of trees in the forest:\n",
    "n_estimators = 100 # default\n",
    "# Number of features to consider when looking for the best split:\n",
    "max_features = 'sqrt' # 'auto' is deprecated\n",
    "# Maximum depth of the tree:\n",
    "max_depth = None\n",
    "# Minimum number of samples required to split an internal node:\n",
    "min_samples_split = 2\n",
    "# Minimum number of samples required to be at a leaf node:\n",
    "min_samples_leaf = 1\n",
    "# Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. \n",
    "max_leaf_nodes = None\n",
    "# Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree:\n",
    "bootstrap = False\n",
    "# Whether to use out-of-bag samples to estimate the generalization score. Only available if bootstrap=True.\n",
    "oob_score = False\n",
    "# Number of jobs to run in parallel. (-1) means use all.\n",
    "n_jobs = -1\n",
    "# Random state\n",
    "random_state = 2023\n",
    "#-----------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance_rf(rfc_model:RandomForestClassifier, feature_names:list):\n",
    "    '''\n",
    "    This function plots the feature importance of the random forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "        rfc_model: Random Forest Classifier model\n",
    "        X_train: Training data set, only for the feature names\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_importance = np.array(rfc_model.feature_importances_)\n",
    "    feature_names = np.array(feature_names)\n",
    "\n",
    "    data={'Feature names':feature_names,'Feature importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    fi_df.sort_values(by=['Feature importance'], ascending=False,inplace=True)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x=fi_df['Feature importance'], y=fi_df['Feature names'])\n",
    "    plt.title('Random Forest Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca841b",
   "metadata": {},
   "source": [
    "### a) Mixed dataset (wrong way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35feea9-0ba5-44a0-8654-ccb4bf33744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the classifier:\n",
    "RFC_demo = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \\\n",
    "                              max_leaf_nodes=max_leaf_nodes, bootstrap=bootstrap,oob_score=oob_score, n_jobs=n_jobs, random_state=random_state)\n",
    "RFC_demo.fit(X_train_mixed, y_train_mixed)\n",
    "RFC_demo.score(X_test_mixed, y_test_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_data_report = Report('rfc_mixed', RFC_demo, X_test_mixed, y_test_mixed, description=['mixed_data', 'raw features'])\n",
    "print(mixed_data_report)\n",
    "precision_recall_multiclass(RFC_demo, X_test_mixed, y_test_mixed)\n",
    "y_pred_mixed = RFC_demo.predict(X_test_mixed)\n",
    "plot_cm(y_test_mixed, y_pred_mixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ce2e8",
   "metadata": {},
   "source": [
    "Too good to be true...<br>\n",
    "This was a demonstration how we should not split the data set!\n",
    "Many people on kaggel etc. made this mistake\n",
    "\n",
    "From now on we will not use this (wrong) processed data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc628b",
   "metadata": {},
   "source": [
    "### b) Custom CV - with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc78cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#Random Forest raw features\n",
    "rf_raw_hyperparams = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'max_leaf_nodes': max_leaf_nodes,\n",
    "                'bootstrap': bootstrap,\n",
    "                'oob_score': oob_score,\n",
    "                'n_jobs': n_jobs,\n",
    "                'random_state': random_state}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_raw, RandomForestClassifier, 'normalize', rf_raw_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec0e68",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d553aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_w_cv_data_report = Report('rfc_raw', best_model, X_test_best, y_test_best, description=['cv_data', 'raw features'])\n",
    "df_results = raw_w_cv_data_report.get_report_as_df(df_results)\n",
    "print(raw_w_cv_data_report)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred_split_raw = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred_split_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbac506",
   "metadata": {},
   "source": [
    "Here we can see that its difficult for the model to classify the \"Fist\" and \"Point2\" data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca51555",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ae44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = df_raw.columns.to_list()\n",
    "feature_list.remove('User')\n",
    "feature_list.remove('Class')\n",
    "plot_feature_importance_rf(best_model, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff838528",
   "metadata": {},
   "source": [
    "### c) Custom CV - with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From now on we will use the following data\n",
    "df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#Random Forest raw features\n",
    "rf_extract_hyperparams = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'max_leaf_nodes': max_leaf_nodes,\n",
    "                'bootstrap': bootstrap,\n",
    "                'oob_score': oob_score,\n",
    "                'n_jobs': n_jobs,\n",
    "                'random_state': random_state}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_aggregate, RandomForestClassifier, 'normalize', rf_extract_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45dba1",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_w_cv_data_report = Report('rfc_extract', best_model, X_test_best, y_test_best, description=['cv_data', 'extracted features'])\n",
    "df_results = extract_w_cv_data_report.get_report_as_df(df_results)\n",
    "print(extract_w_cv_data_report)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred_cv_extract = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred_cv_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b330a",
   "metadata": {},
   "source": [
    "With the extracted features the model improved in predicting \"Point2\" data points, but the perfomance for predicting \"Grab\" decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a49155",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = df_aggregate.columns.to_list()\n",
    "feature_list.remove('User')\n",
    "feature_list.remove('Class')\n",
    "plot_feature_importance_rf(best_model, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5494f",
   "metadata": {},
   "source": [
    "### d) Custom CV - with pca components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb82821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#Random Forest pca features\n",
    "rf_pca_hyperparams = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'max_leaf_nodes': max_leaf_nodes,\n",
    "                'bootstrap': bootstrap,\n",
    "                'oob_score': oob_score,\n",
    "                'n_jobs': n_jobs,\n",
    "                'random_state': random_state}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_pca_features , RandomForestClassifier, 'normalize', rf_pca_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_w_cv_data_report = Report('rfc_pca', best_model, X_test_best, y_test_best, description=['cv_data', 'pca features'])\n",
    "df_results = pca_w_cv_data_report.get_report_as_df(df_results)\n",
    "print(pca_w_cv_data_report)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred_cv_pca = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred_cv_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = df_pca_features.columns.to_list()\n",
    "feature_list.remove('User')\n",
    "feature_list.remove('Class')\n",
    "plot_feature_importance_rf(best_model, feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf1a3af",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "penalty = 'l2'\n",
    "C = 1.0 #regularization strength. The smaller the value, the stronger the regularization.\n",
    "random_state = 2023\n",
    "solver = 'lbfgs' # One of the possible solver for multiclass problems (‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’)\n",
    "max_iter = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965311c8",
   "metadata": {},
   "source": [
    "### a) Custom CV - with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92fde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#Logistic regression raw features\n",
    "lg_raw_hyperparams = {'penalty': penalty,\n",
    "                'C': C,\n",
    "                'random_state': random_state,\n",
    "                'solver': solver,\n",
    "                'max_iter': max_iter}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_raw, LogisticRegression, 'standard', lg_raw_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d681f10a",
   "metadata": {},
   "source": [
    "Error occured:\n",
    "ConvergenceWarning: lbfgs failed to converge (status=1)\n",
    "-> increase max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ac0e8",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_w_cv_data_report_lg = Report('lg_raw', best_model, X_test_best, y_test_best, description=['LogReg', 'cv_data', 'raw features'])\n",
    "df_results = raw_w_cv_data_report_lg.get_report_as_df(df_results)\n",
    "print(raw_w_cv_data_report_lg)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5efb2",
   "metadata": {},
   "source": [
    "### b) Custom CV - with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#Logistic regression extract features\n",
    "lg_extract_hyperparams = {'penalty': penalty,\n",
    "                'C': C,\n",
    "                'random_state': random_state,\n",
    "                'solver': solver,\n",
    "                'max_iter': max_iter}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_aggregate, LogisticRegression, 'standard', lg_extract_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a2be5",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_w_cv_data_report_lg = Report('lg_extract', best_model, X_test_best, y_test_best, description=['LogReg', 'cv_data', 'extracted features'])\n",
    "df_results = extract_w_cv_data_report_lg.get_report_as_df(df_results)\n",
    "print(extract_w_cv_data_report_lg)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd3e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08235963",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19328cee",
   "metadata": {},
   "source": [
    "### a) Custom CV - with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96991f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#SVC_raw\n",
    "svc_raw_hyperparams = {\n",
    "    'C': 1.0, #regularization strength. The smaller the value, the stronger the regularization.\n",
    "    'gamma':'scale',\n",
    "    'kernel': 'rbf',\n",
    "    'decision_function_shape': 'ovo',\n",
    "    'random_state': 2023,\n",
    "    'max_iter': -1, # -1 means no limit\n",
    "    'cache_size': 200, # in MB\n",
    "    'probability': True # needed for predict_proba later on\n",
    "}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_raw, SVC, 'standard', svc_raw_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a90c1",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06212600",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_w_cv_data_report_svm = Report('svm_raw', best_model, X_test_best, y_test_best, description=['SVM', 'cv_data', 'raw features'])\n",
    "df_results = raw_w_cv_data_report_svm.get_report_as_df(df_results)\n",
    "print(raw_w_cv_data_report_svm)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f68ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6f14d",
   "metadata": {},
   "source": [
    "### b) Custom CV - with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#SVC_aggregate\n",
    "svc_extract_hyperparams = {\n",
    "    'C': 1.0, #regularization strength. The smaller the value, the stronger the regularization.\n",
    "    'gamma':'scale',\n",
    "    'kernel': 'rbf',\n",
    "    'decision_function_shape': 'ovo',\n",
    "    'random_state': 2023,\n",
    "    'max_iter': -1, # -1 means no limit\n",
    "    'cache_size': 200, # in MB\n",
    "    'probability': True # needed for predict_proba later on\n",
    "}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_aggregate, SVC, 'standard', svc_extract_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09d117",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2577b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_w_cv_data_report_svm = Report('svm_extract', best_model, X_test_best, y_test_best, description=['SVM', 'cv_data', 'extracted features'])\n",
    "df_results = extract_w_cv_data_report_svm.get_report_as_df(df_results)\n",
    "print(extract_w_cv_data_report_svm)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27262a2f",
   "metadata": {},
   "source": [
    "### c) Custom CV - with pca features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#SVC_pca\n",
    "svc_pca_hyperparams = {\n",
    "    'C': 1.0, #regularization strength. The smaller the value, the stronger the regularization.\n",
    "    'gamma':'scale',\n",
    "    'kernel': 'rbf',\n",
    "    'decision_function_shape': 'ovo',\n",
    "    'random_state': 2023,\n",
    "    'max_iter': -1, # -1 means no limit\n",
    "    'cache_size': 200, # in MB\n",
    "    'probability': True # needed for predict_proba later on\n",
    "}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_pca_features, SVC, 'standard', svc_pca_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a84d5",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab157a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_w_cv_data_report_svm = Report('svm_pca', best_model, X_test_best, y_test_best, description=['SVM', 'cv_data', 'pca features'])\n",
    "df_results = pca_w_cv_data_report_svm.get_report_as_df(df_results)\n",
    "print(pca_w_cv_data_report_svm)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred_pca_svm = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred_pca_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9bdd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd66664-7712-40e8-824c-ba7baf5ea7bb",
   "metadata": {},
   "source": [
    "### Grid Search - with extracted data and raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501f080-8c60-41de-b337-3531c4e5037f",
   "metadata": {},
   "source": [
    "#### I. Grid Search with extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ad3a43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac462fcd-8d93-4519-aa6c-b6e58567f8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want to run a GridSearch without internal CV!\n",
    "# We will run our own CV-Split because we have to split by User!\n",
    "# Have a look at this thread If you are interested: https://stackoverflow.com/questions/44636370/scikit-learn-gridsearchcv-without-cross-validation-unsupervised-learning/44682305#44682305\n",
    "param_grid = {'C':[1,10,100,1000],\n",
    "              'gamma':[1,0.1,0.001,0.0001],\n",
    "              'kernel':['linear','rbf']} # alternative for C space: use np.logspace\n",
    "\n",
    "static_params = {'decision_function_shape': 'ovo',\n",
    "                    'random_state': 2023,\n",
    "                    'max_iter': -1, # -1 means no limit\n",
    "                    'cache_size': 200, # in MB\n",
    "                    'probability': True # needed for predict_proba later on\n",
    "}\n",
    "\n",
    "# Add static params to param_grid\n",
    "#param_grid.update(static_params)\n",
    "\n",
    "svc_extract_search = {'estimator': SVC(**static_params),\n",
    "                      'param_grid': param_grid,\n",
    "                      'refit' : False, #We later want to refit only on X_train, y_train\n",
    "                      'scoring': 'accuracy',\n",
    "                      'verbose': 2,\n",
    "                      'n_jobs': -1\n",
    "}\n",
    "cv_k = 3 # Number CV folds\n",
    "model, X_test_best, y_test_best, grid_search_list = grid_search(df_aggregate, SVC, 'standard', cv_k, svc_extract_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b593805",
   "metadata": {},
   "source": [
    "TODO other models to try <br>\n",
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b65fc8-21b1-4c44-af6f-d72ee26c24a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_grid_search(grid_search_list, grid_param_1, grid_param_2):\n",
    "    \n",
    "    for idx, grid_search in enumerate(grid_search_list):\n",
    "        print('Grid Search #', idx)\n",
    "        data = grid_search.cv_results_\n",
    "    \n",
    "        # extract relevant data\n",
    "        params = [d[grid_param_1] for d in data['params']]\n",
    "        param2_values = sorted(list(set([d[grid_param_2] for d in data['params']])))\n",
    "        scores = data['mean_test_score']#np.array([d['mean_test_score'] for d in data])\n",
    "\n",
    "        # create figure\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        # plot scores for each value of param2\n",
    "        for i, param2_value in enumerate(param2_values):\n",
    "            x = [params[j] for j in range(len(params)) if data['params'][j][grid_param_2] == param2_value]\n",
    "            y = [scores[j] for j in range(len(params)) if data['params'][j][grid_param_2] == param2_value]\n",
    "\n",
    "            # Get all indices with the same x value:\n",
    "            # get unique values and their counts\n",
    "            unique_values, value_counts = np.unique(x, return_counts=True)\n",
    "            # loop through unique values and get indices of elements with that value\n",
    "            indices_by_value = []\n",
    "            for value in unique_values:\n",
    "                indices_by_value.append(np.where(x == value)[0])\n",
    "            x = unique_values\n",
    "            # Calculate the mean of y values that have the same x value\n",
    "            y = [np.mean([y[i] for i in indices_by_value[k]]) for k in range(len(unique_values))]\n",
    "            \n",
    "            ax.plot(x, y, label=f'{grid_param_2}={param2_value}')\n",
    "\n",
    "        # set axis labels and legend\n",
    "        ax.set_xlabel(grid_param_1)\n",
    "        ax.set_ylabel('Mean Test Score')\n",
    "        ax.legend(title=grid_param_2)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dee54d-adae-4e30-a573-af4200344fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_grid_search(grid_search_list, 'C', 'kernel')\n",
    "plot_grid_search(grid_search_list, 'C', 'gamma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf22b4-752a-4410-82d6-f4af067913ad",
   "metadata": {},
   "source": [
    "#### II. Grid Search with raw features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46929272-8b6e-476f-a501-1fec20e38d2c",
   "metadata": {},
   "source": [
    "We want to search in the same parameter space that we used for grid search with the extracted features. Therefore we simply have to call the grid_search function with the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228aca30-228d-4a4e-a1c1-14c137ff01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X_test_best, y_test_best, grid_search_list = grid_search(df_raw, SVC, 'standard', cv_k, svc_extract_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9f4a6-4c9e-442b-8cf0-6771b9fe61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search(grid_search_list, 'C', 'kernel')\n",
    "plot_grid_search(grid_search_list, 'C', 'gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da30056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO boxplot of the results\n",
    "'''\n",
    "ax = sns.boxplot(data = f2_df, linewidth=1, showfliers=False)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "sns.set(rc = {'figure.figsize':(8,10)})\n",
    "ax.set(ylabel='F2-Score')\n",
    "ax.set_title('F2-Score Deviation of different Models')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57427d49",
   "metadata": {},
   "source": [
    "## Conclusion Testing Phase I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66077b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison(df_results):\n",
    "    '''\n",
    "    Plot a comparison of the models based on the evaluation metrics\n",
    "    '''\n",
    "\n",
    "    df = df_results.copy()\n",
    "    # Set the model as the index\n",
    "    df.set_index('model', inplace=True)\n",
    "    # Create a 2x2 grid of subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "    # Create color list\n",
    "    colors = ['tab:blue', 'tab:red', 'tab:green', 'tab:orange', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "\n",
    "    # Plot each metric in a subplot\n",
    "    for i, metric in enumerate(df.columns):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        axs[row, col].bar(df.index, df[metric], color=colors[:len(df.index)], width=0.3)\n",
    "        axs[row, col].set_xticklabels(df.index.to_list(), rotation=90)\n",
    "        axs[row, col].set_ylabel(metric)\n",
    "        axs[row, col].set_title(f'{metric} Comparison')\n",
    "        axs[row, col].set_ylim([0, 1])\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    plt.tight_layout()\n",
    "    # Display the plots\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results\n",
    "plot_model_comparison(df_results)\n",
    "best_score = df_results.iloc[df_results['Accuracy'].idxmax()]\n",
    "print('**Model with highest accuracy score**')\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4539e6b0",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Extracted features?\n",
    "* good, we see an improvement ...\n",
    "\n",
    "Confusion Matrix:\n",
    "* what cases are difficult\n",
    "* which are easy\n",
    "* explanation why\n",
    "\n",
    "Feature reduction\n",
    "* good/bad\n",
    "* PCA\n",
    "* which models got worses\n",
    "\n",
    "Best model:\n",
    "* e.g. rf with extracted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7e387-b801-43da-ba43-81f3c958aad4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Testing Phase II: Model Developement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994e566",
   "metadata": {},
   "source": [
    "Help Section:<br>\n",
    "You have problems that the kernel freezes mulitple times while training? The Training process seems to run in the background and hence there will appear new models (if you save them as pickle files).\n",
    "But there is no information that the training process finished (running forever)\n",
    "follow this thread:<br>\n",
    "https://stackoverflow.com/questions/52261597/keras-model-fit-verbose-formatting <br>\n",
    "and install:\n",
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5326581a",
   "metadata": {},
   "source": [
    "## Base MLP structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bd1af",
   "metadata": {},
   "source": [
    "* Activation Functions\n",
    "    - output layer: one neuron for each class (5)\n",
    "    - we want the the probability of the each class, -> **softmax**\n",
    "    - hidden Layer: start with **ReLU**\n",
    "\n",
    "* Optimizer\n",
    "    - **rmsprop**\n",
    "\n",
    "* loss\n",
    "    - **categorical_crossentropy**\n",
    "\n",
    "* Hidden Layers and Number of Neurons\n",
    "    - start with small architecture, increase size\n",
    "\n",
    "* Metric\n",
    "    - **accuracy**\n",
    "    - **precission**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562b4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def build_mlp_model(name:str, hyperparams:dict, input_shape: tuple, output_shape: int) -> keras.Sequential:\n",
    "    'Build MLP classification network'\n",
    "\n",
    "    if hyperparams['hidden_layer'] != len(hyperparams['units_hidden_layer']):\n",
    "        raise ValueError('Number of hidden layers and values provided for number of units per hidden layer do not match')\n",
    "    \n",
    "    # Use l1, l2 regularization?\n",
    "    if hyperparams['weight regularisation l1'] and hyperparams['weight regularisation l2']:\n",
    "        kernel_regu = keras.regularizers.L1L2(l1=hyperparams['weight regularisation l1'],\n",
    "                                              l2=hyperparams['weight regularisation l2'])\n",
    "    elif hyperparams['weight regularisation l1']:\n",
    "        kernel_regu = keras.regularizers.L1(l1=hyperparams['weight regularisation l1'])\n",
    "    elif hyperparams['weight regularisation l2']:\n",
    "        kernel_regu = keras.regularizers.L2(l2=hyperparams['weight regularisation l2'])\n",
    "    else: # Do not use regularization\n",
    "        kernel_regu = None\n",
    "\n",
    "    model = keras.Sequential(name=name)\n",
    "    model.add(keras.Input(shape=input_shape))\n",
    "\n",
    "    # Hidden Layer\n",
    "    for num_hl in range(hyperparams['hidden_layer']):\n",
    "        model.add(layers.Dense(hyperparams['units_hidden_layer'][num_hl],\n",
    "                               activation=hyperparams['activation_hidden'],\n",
    "                               kernel_initializer=hyperparams['kernel_initializer'],\n",
    "                               bias_initializer=hyperparams['bias_initializer'],\n",
    "                               kernel_regularizer=kernel_regu\n",
    "                               ))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(rate=hyperparams['dropout']))\n",
    "\n",
    "    model.add(layers.Dense(output_shape, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=hyperparams['optimizer'], loss=hyperparams['loss'], metrics=hyperparams['metrics'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7f9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(hist, parameters, name:str):\n",
    "    \n",
    "    plt.plot(hist['epoch'][:],hist['loss'][:], \"k--\", linewidth=1.5, label=\"Training\")\n",
    "    plt.plot(hist['epoch'][:],hist['val_loss'][:], \"b-.\", linewidth=1.5, label=\"CV test\")\n",
    "    plt.legend()\n",
    "    plt.ylim(0,max(hist['loss'][:].max(), hist['val_loss'][:].max())+0.2)\n",
    "    plt.xlabel(\"Epochs\"),  plt.ylabel(\"categorical_crossentropy\")\n",
    "\n",
    "    plt.title(f'Learning Curve: {name}', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65c2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_multiple_learning_curves(name, hyperparams):\n",
    "    \"\"\"\n",
    "    Plot the learning curves for each cv run\n",
    "    \"\"\"\n",
    "\n",
    "    # Load hist of every cv run\n",
    "\n",
    "    all_hist = []\n",
    "\n",
    "    for i in range(4):\n",
    "        hist = load_history(f'{name}_cv{i}')\n",
    "        all_hist.append(hist)\n",
    "        \n",
    "    # Plot the learning curves for each cv run\n",
    "    for i in range(4):\n",
    "        plot_learning_curves(all_hist[i], hyperparams, f'{name}_cv{i}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25776e73-0674-45e3-bba6-bfcbf8266e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_curves(hist, parameters, name:str):\n",
    "    '''\n",
    "    Plot the accuracy curves of the training and test set\n",
    "    '''\n",
    "    \n",
    "    plt.plot(hist['epoch'][:],hist['categorical_accuracy'][:], \"k--\", linewidth=1.5, label=\"Training\")\n",
    "    plt.plot(hist['epoch'][:],hist['val_categorical_accuracy'][:], \"b-.\", linewidth=1.5, label=\"CV test\")\n",
    "    plt.legend()\n",
    "    plt.ylim(0,1.0)\n",
    "    plt.xlabel(\"Epochs\"),  plt.ylabel(\"categorical_accuracy\")\n",
    "\n",
    "    plt.title(f'Accuracy Curve: {name}', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c499a7-f83b-42d4-b131-3f043ff3104b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_multiple_acc_curves(name, hyperparams):\n",
    "    \"\"\"\n",
    "    Plot the accuracy curves for each cv run\n",
    "    \"\"\"\n",
    "\n",
    "    # Load hist of every cv run\n",
    "\n",
    "    all_hist = []\n",
    "\n",
    "    for i in range(4):\n",
    "        hist = load_history(f'{name}_cv{i}')\n",
    "        all_hist.append(hist)\n",
    "        \n",
    "    # Plot the accuracy curves for each cv run\n",
    "    for i in range(4):\n",
    "        plot_accuracy_curves(all_hist[i], hyperparams, f'{name}_cv{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97854963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_history(hist, name):\n",
    "\n",
    "    # Get path to save the history\n",
    "    hist_folder = 'model/single_run/history'\n",
    "    model_path = join(hist_folder, name)\n",
    "    \n",
    "    with open(model_path, 'wb') as file_pi:\n",
    "        pickle.dump(hist, file_pi)\n",
    "\n",
    "def load_history(name):\n",
    "\n",
    "    # Get path to save the history\n",
    "    hist_folder = 'model/single_run/history'\n",
    "    model_path = join(hist_folder, name)\n",
    "    \n",
    "    with open(model_path, 'rb') as file_pi:\n",
    "        history = pickle.load(file_pi)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e74265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(name):\n",
    "\n",
    "    # Get path to save the history\n",
    "    model_folder = 'model/single_run'\n",
    "    model_path = join(model_folder, name)\n",
    "    \n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a376ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_used_parameters(parameters:dict):\n",
    "    print('Used parameters:')\n",
    "    for parameter, value in parameters.items():\n",
    "        print(f'{parameter}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a319e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_one_hot(one_hot_encoded):\n",
    "    return np.argmax(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb396a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_f1_score_mlp(model, X, y):\n",
    "    # Calculate f1 score of mlp\n",
    "    y_pred1 = model.predict(X)\n",
    "    y_pred = np.argmax(y_pred1, axis=1)\n",
    "\n",
    "    # to one hot encoding\n",
    "    y_pred = to_categorical(y_pred)\n",
    "\n",
    "    return f1_score(y, y_pred , average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda9460a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_k_mlp_model(name, df:pd.DataFrame, hyperparams:dict):\n",
    "    '''\n",
    "    Train a MLP model with k-fold cross validation (leave n users out strategy)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str, Name of the model.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    best_model : keras.Sequential, The best model.\n",
    "    best_acc : float, The best accuracy.\n",
    "    X_test_best : numpy.ndarray, The best test set.\n",
    "    y_test_best : numpy.ndarray, The best test set.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    # Create a list of users\n",
    "    user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "    # Number of users to be used for the test set\n",
    "    num_user_test = 3\n",
    "    num_of_iterations = 4\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    X_test_best = None\n",
    "    y_test_best = None\n",
    "\n",
    "    all_acc_val = []\n",
    "    all_prec_val = []\n",
    "\n",
    "    # Evaluation dict\n",
    "    eval_dict = {'train': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []},\n",
    "                 'test': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []}}\n",
    "\n",
    "    describe_model = True\n",
    "\n",
    "    for i in range(num_of_iterations):\n",
    "\n",
    "        print('*'*50)\n",
    "        print(f'CV Run: {i}')\n",
    "\n",
    "        # Split the data #TODO rename to X_train etc. because function also use by raw and later pca\n",
    "        X_train_cv_extract, y_train_cv_extract, X_test_cv_extract, y_test_cv_extract, user_list = custom_cv_approach(df, user_list, num_user_test=num_user_test)\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train_cv_extract)\n",
    "        X_train_cv_extract = scaler.transform(X_train_cv_extract)\n",
    "        X_test_cv_extract = scaler.transform(X_test_cv_extract)\n",
    "        # Befor one hot encoding, class has to start at 0\n",
    "        y_train_cv_extract = y_train_cv_extract-1\n",
    "        y_test_cv_extract = y_test_cv_extract-1\n",
    "        # y label to one hot encode\n",
    "        y_train_cv_extract = to_categorical(y_train_cv_extract)\n",
    "        y_test_cv_extract = to_categorical(y_test_cv_extract)\n",
    "\n",
    "        # Build the model\n",
    "        # TODO\n",
    "        mlp_model = build_mlp_model(name, hyperparams, input_shape=X_train_cv_extract.shape[1:], output_shape=y_train_cv_extract.shape[1])\n",
    "\n",
    "        # Only print the model summary once\n",
    "        if describe_model:\n",
    "            mlp_model.summary()\n",
    "            describe_model = False\n",
    "\n",
    "        # Create callback\n",
    "        # Use early stopping later because it is a form of regularization\n",
    "        #early_stop_callback = keras.callbacks.EarlyStopping(monitor=\"val_categorical_accuracy\", min_delta=1e-4, patience=5, verbose=1)\n",
    "        checkpoint_callback = keras.callbacks.ModelCheckpoint(f'model/single_run/{name}_cv{i}.h5', save_best_only=True)\n",
    "        \n",
    "        callbacks = [TqdmCallback(verbose=0), checkpoint_callback]\n",
    "        if hyperparams['reduce_lr']:\n",
    "            reduce_lr_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.2,\n",
    "                                           patience=5, min_lr=0.00001,\n",
    "                                           min_delta=0.001)\n",
    "            callbacks.append(reduce_lr_callback)\n",
    "\n",
    "        # Train the model\n",
    "        history = mlp_model.fit(X_train_cv_extract, \n",
    "                                y_train_cv_extract, \n",
    "                                epochs=hyperparams['num_epochs'], \n",
    "                                batch_size= hyperparams['batch_size'],\n",
    "                                validation_data=(X_test_cv_extract, y_test_cv_extract),\n",
    "                                verbose=0,\n",
    "                                shuffle=True,\n",
    "                                callbacks=[TqdmCallback(verbose=0), checkpoint_callback])\n",
    "\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "\n",
    "        # Save the history\n",
    "        save_history(hist, f'{name}_cv{i}')\n",
    "\n",
    "        #Evaluating the training performance:\n",
    "        train_loss, train_acc, train_precision, train_recall = mlp_model.evaluate(x=X_train_cv_extract, y=y_train_cv_extract, batch_size=hyperparams['batch_size'], verbose=3)\n",
    "        f1_score_train = calc_f1_score_mlp(mlp_model, X_train_cv_extract, y_train_cv_extract)\n",
    "\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'train', train_acc, train_precision, train_recall, f1_score_train)\n",
    "        print('-'*70)\n",
    "        print('Evaluation of training Data: \\n', 'training loss: ', train_loss, 'training accuracy: ', train_acc)\n",
    "\n",
    "        #Evaluating the CV pperformance:\n",
    "        val_loss, val_acc, val_precision, val_recall = mlp_model.evaluate(x=X_test_cv_extract, y=y_test_cv_extract, batch_size=hyperparams['batch_size'], verbose=0)\n",
    "        f1_score_test = calc_f1_score_mlp(mlp_model, X_test_cv_extract, y_test_cv_extract)\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'test', val_acc, val_precision, val_recall, f1_score_test)\n",
    "        all_acc_val.append(val_acc)\n",
    "        all_prec_val.append(val_precision)\n",
    "        print('Evaluation of validation Data: \\n', 'cv loss: ', val_loss, 'cv accuracy: ', val_acc)\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_model = mlp_model\n",
    "            best_acc = val_acc\n",
    "            X_test_best = X_test_cv_extract\n",
    "            y_test_best = y_test_cv_extract\n",
    "\n",
    "    #Lets see the overall score as average of the scores of all the folds:\n",
    "    print('-'*70)\n",
    "    print('(all CV runs combined)')\n",
    "    print('Mean Accuracy  for the validation dataset: ', np.mean(all_acc_val))\n",
    "    print('Mean Precision for the validation dataset: ', np.mean(all_prec_val))\n",
    "    print('-'*70)\n",
    "\n",
    "    # Save the model\n",
    "    best_model.save(f'model/single_run/{name}_best_model.h5')\n",
    "\n",
    "    # Save the evaluation dict\n",
    "    save_eval_dict_pkl(eval_dict, f'{name}_eval_dict')\n",
    "\n",
    "    # Plot the learning curves\n",
    "    plot_learning_curves(hist, hyperparams, name)\n",
    "\n",
    "    return best_model, best_acc, X_test_best, y_test_best, eval_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5efe257e",
   "metadata": {},
   "source": [
    "### Methodology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaed85ad",
   "metadata": {},
   "source": [
    "<ins>Disclaimer</ins>: If you are only interested in the results, you can skip this section! I would like to guarantee a red thread here and show that the models did not fall from the sky like this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72d25e83",
   "metadata": {},
   "source": [
    "Since I adjusted hyperparameters several times in the following sections, I would like to give the reader a brief overview here of how the adjustment steps went:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a456c613",
   "metadata": {},
   "source": [
    "1. Model seems to overfit from the very beginning <br>\n",
    "I used a structure like this:<br>\n",
    "number of neurons in the hidden layers: [32, 64, 64, 32, 16]<br>\n",
    "<img src=\"img/overfit_big_model.png\" width=330 height=310 /> <br>\n",
    "I decided to reduce the number neurons and layers. The new structure looked like this:<br>\n",
    "number of neurons in the hidden layers: [16, 16, 8]<br>\n",
    "<img src=\"img/overfit_small_model.png\" width=330 height=310 /> <br>\n",
    "I added Batch normalization and drop out layer to prevent the model from overfitting. <br>\n",
    "Problem still seemed to be presence. So I reduced the network complexity even further:<br>\n",
    "number of neurons in the hidden layers: [8, 8, 8]<br>\n",
    "<img src=\"img/underfit.png\" width=330 height=310 /> <br>\n",
    "Now the model was underfitting. The training loss was not decreasing that much after a few epochs. The validation loss was on a same level. Another thing I was wondering about was the weird behaviour of the validation loss. Right from the beginning of training it was increasing and the curve has fluctuated very strongly.\n",
    "\n",
    "2. Validation loss is more fluctuating then the training loss<br>\n",
    "After some internet reasearch I got inspiration what to look for. I have added more validation data as it may not be representative of the data. Now I selected three user for the validation data instead of instead of two.\n",
    "3. Check preprocessing:\n",
    "Some posts also suggested two have a look into my preprocessing steps. Some people suggested I might have processed the validation and the training data in a different way\n",
    "I did not shuffle the data!\n",
    "```python\n",
    "model.fit(..., shuffle=True) #Keras model\n",
    "```\n",
    "-> only shuffels the training set!! not the the validation set\n",
    "\n",
    "4. First real baseline model\n",
    "After decreasing the learning rate and increased the drop out rate for the drop out layer, I got a quiet descent MLP model: <br>\n",
    "<img src=\"img/baseline_model.png\" width=330 height=310 /> <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d357fe",
   "metadata": {},
   "source": [
    "### a) Custom CV - with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a1c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hyperparams = {'num_epochs': 35, # 35,\n",
    "               'batch_size': 32,\n",
    "               'hidden_layer': 3,\n",
    "               'units_hidden_layer': [16, 16, 8],#[64, 64, 32, 16],\n",
    "               'activation_hidden': keras.layers.LeakyReLU(alpha=0.1), #'LeakyReLU' #'relu',\n",
    "               'activation_output': 'softmax',\n",
    "               'loss': 'categorical_crossentropy',\n",
    "               'metrics': ['categorical_accuracy', 'Precision', tf.keras.metrics.Recall()],\n",
    "               'optimizer': keras.optimizers.legacy.Adam(learning_rate=0.00005), #0.0003\n",
    "               'kernel_initializer': 'he_normal', # used for ReLU activation function\n",
    "               'bias_initializer': 'zeros',\n",
    "               'initialization': '-',\n",
    "               'weight regularisation l1': '',\n",
    "               'weight regularisation l2': '',\n",
    "               'dropout': 0.35,  # typically between 0.3 and 0.5 (half of weights get 0)\n",
    "               'early Stopping': 'False',\n",
    "               'reduce_lr': False} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aad82d",
   "metadata": {},
   "source": [
    "To get an Idea How long the model trains: <br>\n",
    "22min for 4 runs\n",
    "* each trains for 35 epochs\n",
    "\n",
    "Highly depends on the used Hardware! <br>\n",
    "Here we use an M1 macbook with GPU tf vesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'mlp_base_model_raw'\n",
    "df = df_raw\n",
    "best_model, best_acc, X_test_best, y_test_best, eval_dict = train_k_mlp_model(name, df, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_learning_curves(name, {'test': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc184952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust to mlp, KeyError: 'accuracy'\n",
    "data_report_mlp_base_raw = Report('mlp_raw', best_model, X_test_best, y_test_best, description=['MLP base', 'cv_data', 'raw features'])\n",
    "#df_results = data_report_mlp_base_raw.get_report_as_df(df_results)\n",
    "print(data_report_mlp_base_raw)\n",
    "\n",
    "# Prepare data to be compatible with confusion matrix function\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "y_pred = np.argmax(y_pred, axis=1)+1\n",
    "y_test_int = np.argmax(y_test_best, axis=1)+1\n",
    "plot_cm(y_test_int, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741bae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad78e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mode = 'retrain' # 'retrain' or 'load_model'\n",
    "if run_mode == 'load_model':\n",
    "    hist = load_history('mlp_base_model_raw_cv3')\n",
    "    plot_learning_curves(hist, hyperparams, 'test')\n",
    "    eval_dict = load_eval_dict_pkl('mlp_base_model_raw_eval_dict')\n",
    "    plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e337a",
   "metadata": {},
   "source": [
    "First I tried a model with 32 16 8 units in the hidden layer<br>\n",
    "the validation los increased rigth from the beginning while the test loss was decreasing, which is a sign of overfitting<br>\n",
    "insert pic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00860b9",
   "metadata": {},
   "source": [
    "### b) Custom CV - with extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98938d2b",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a6921-57fc-4646-b89c-00decf84d2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I figured out the the model trained with extracted features need more epochs\n",
    "hyperparams['num_epochs'] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836b70a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'mlp_base_model_extracted'\n",
    "df = df_aggregate\n",
    "best_model, best_acc, X_test_best, y_test_best, eval_dict = train_k_mlp_model(name, df, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da2eeb-6b7a-4ec0-8cc0-2ee59f7a05ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_report_mlp_base_extract = Report('mlp_extract', best_model, X_test_best, y_test_best, description=['MLP base', 'cv_data', 'extract features'])\n",
    "#df_results = data_report_mlp_base_raw.get_report_as_df(df_results)\n",
    "print(data_report_mlp_base_extract)\n",
    "\n",
    "# Prepare data to be compatible with confusion matrix function\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "y_pred = np.argmax(y_pred, axis=1)+1\n",
    "y_test_int = np.argmax(y_test_best, axis=1)+1\n",
    "plot_cm(y_test_int, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b1e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d563fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_multiple_learning_curves(name, {'test': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd69e5c-5489-4647-9105-be5abf7b6e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_multiple_acc_curves(name, {'test': 'test'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c4933",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878b8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO save hist in list or load hist of every model and plot learning curve of every cv model\n",
    "# retrain model on whole data (validation + train) leave one user out as test set (instead of best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfad07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_report_mlp_base_raw = Report('mlp_extract', best_model, X_test_best, y_test_best, description=['MLP base', 'cv_data', 'extracted features'])\n",
    "#df_results = data_report_mlp_base_raw.get_report_as_df(df_results)\n",
    "print(data_report_mlp_base_raw)\n",
    "\n",
    "# Prepare data to be compatible with confusion matrix function\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "y_pred = np.argmax(y_pred, axis=1)+1\n",
    "y_test_int = np.argmax(y_test_best, axis=1)+1\n",
    "plot_cm(y_test_int, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe123af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1850e8c-439b-410d-94b3-d75cd8b4c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS\n",
    "# Now we have base mlp model that we trained in a stable way (no big fluctuations etc.) and which is also not overfitting\n",
    "# This should be a good starting point for a hyperparameter search and fine tuning of regularization technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75eacfa-984f-4b53-b8ef-3d0d086e4c7b",
   "metadata": {},
   "source": [
    "### c) Custom CV -with pca data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c4d41-bc20-423a-805f-181760f6b119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'mlp_base_model_pca'\n",
    "df = df_pca_features\n",
    "best_model, best_acc, X_test_best, y_test_best, eval_dict = train_k_mlp_model(name, df, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44576068-c45e-4f37-8787-ffd2e140a3af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_multiple_learning_curves(name, {'test': 'test'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57623d49",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6121db1",
   "metadata": {},
   "source": [
    "Already training the baseline MLP models has required several iterative fits. Partial regularization methods were already used, e.g. dropout layer. In this section, however, these were only applied to be able to train the model correctly at all.\n",
    "\n",
    "(In section 3 more regularization methods are used and fine tuned to achieve the best model performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0d448",
   "metadata": {},
   "source": [
    "## PointNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f5969",
   "metadata": {},
   "source": [
    "Note: for this archtitecture we have to use the original, raw data because we need a Point Cloud!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dad2d5",
   "metadata": {},
   "source": [
    "From the Paper: \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" (Charles R. Qi et al)\n",
    "https://arxiv.org/abs/1612.00593"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de8251",
   "metadata": {},
   "source": [
    "DISCLAIMER:\n",
    "Implementation with Keras:<br>\n",
    "https://keras.io/examples/vision/pointnet/\n",
    "\n",
    "Here we replicate the network architecture published in the original paper with the help of this blogpost!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180ad6b",
   "metadata": {},
   "source": [
    "General\n",
    "* Point cloud =  a geometric data structure with irregular format\n",
    "* paper proposes a novel neural network called PointNet\n",
    "* PointNet: directly consumes point clouds + respects the permutation invariance of points in the input\n",
    "* unified architecture for object classification, part segmentation, and scene semantic parsing\n",
    "* simple, efficient, and effective\n",
    "\n",
    "Architecture\n",
    "* deal with unordered input set: use of a single symmetric function, max pooling\n",
    "* network learns a set of optimization functions/criteria that select interesting or informative points of the point cloud and encode the reason for their selection\n",
    "* final fully connected layers: aggregate these learnt optimal values into the global descriptor for the entire shape (shape classification) or are used to predict per point labels (shape segmentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df0649",
   "metadata": {},
   "source": [
    "Each convolution and fully-connected layer (with exception for end layers) consits of \n",
    "* Convolution / Dense\n",
    "* Batch Normalization\n",
    "* ReLU Activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a58e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5fc07b",
   "metadata": {},
   "source": [
    "PointNet consists of two core components\n",
    "* primary MLP network\n",
    "* transformer net (T-net)\n",
    "    * aims to learn an affine transformation matrix by its own mini network\n",
    "    * used twice:\n",
    "        * 1.to transform the input features (n, 3) into a canonical representation\n",
    "        * 2.affine transformation for alignment in feature space (n, 3)\n",
    "\n",
    "What will we do?\n",
    "* implement main network \n",
    "* drop the t-net mini models as layers in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f788f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "    \n",
    "    def get_config(self): #TODO required for saving model\n",
    "        return {'test': 'test'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnet(inputs, num_features):\n",
    "    '''Build T-net layers'''\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "\n",
    "    x = conv_bn(inputs, 8) # Original 32 in paper\n",
    "    x = conv_bn(x, 32) # Original 64 in paper\n",
    "    x = conv_bn(x, 64) # Original 512 in paper\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 32) # Original 256 in paper\n",
    "    x = dense_bn(x, 8) # Original 128 in paper\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfdcd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pointnet(num_points, num_classes):\n",
    "    '''Use the functional API to build a PointNet model (different from the Sequential API)'''\n",
    "    inputs = keras.Input(shape=(num_points, 3))\n",
    "\n",
    "    x = tnet(inputs, 3)\n",
    "    x = conv_bn(x, 16) #OG 32\n",
    "    x = conv_bn(x, 16) #OG 32\n",
    "    x = tnet(x, 16) #OG 32\n",
    "    x = conv_bn(x, 16) #OG 32\n",
    "    x = conv_bn(x, 16) #OG 64\n",
    "    x = conv_bn(x, 32) #OG 512\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 64) #OG 256\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = dense_bn(x, 32) #OG 128\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17437083",
   "metadata": {},
   "source": [
    "Now we have all utility functions we need for our PointNet model<br>\n",
    "We have to preprocess the input data to be compatible with the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd660fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cv_approach_point_clouds(np_batches:np.array, df:pd.DataFrame, user_list:list, num_user_test:int=2) -> Tuple[np.array, np.array, np.array, np.array, list]:\n",
    "    '''\n",
    "    MODIFIED for point cloud data\n",
    "    each user is iteratively left out from training and used as a test set. \n",
    "    We then tests the generalization of the algorithm to new users. \n",
    "    A 'User' attribute is provided to accomodate this strategy. \n",
    "    '''\n",
    "\n",
    "    def cv_ratio(y_test, df):\n",
    "        print(f'Ratio of test set: {len(y_test)/len(df)}')\n",
    "    \n",
    "    # Get the indices for the training and test set\n",
    "    train_indices, test_indices, user_list = get_train_test_user(df, user_list, num_user_test)\n",
    "    # Shuffle data\n",
    "    shuffle(train_indices)\n",
    "    shuffle(test_indices)\n",
    "    print(f'train_indices examples: {len(train_indices)}')\n",
    "    print(f'test_indices examples: {len(test_indices)}')\n",
    "    # Create the training and test set\n",
    "    # MODIFIED for point cloud data\n",
    "    X_train = np_batches[train_indices, :, :]\n",
    "    y_train = df.iloc[train_indices, :]['Class']\n",
    "    X_test = np_batches[test_indices, :, :]\n",
    "    y_test = df.iloc[test_indices, :]['Class']\n",
    "\n",
    "    cv_ratio(y_test, df)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_pn_model(name, np_batches:np.array, df:pd.DataFrame, hyperparams:dict):\n",
    "    '''\n",
    "    Train multiple PointNet models with k-fold cross validation (leave n users out strategy)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str, Name of the model.\n",
    "    np_batches : numpy.ndarray, The data.\n",
    "    df : pandas.DataFrame, We will use this dataframe ONLY to get the labels.\n",
    "    hyperparams : dict, The hyperparameters.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    best_model : keras.Sequential, The best model.\n",
    "    best_acc : float, The best accuracy.\n",
    "    X_test_best : numpy.ndarray, X_test set\n",
    "    y_test_best : numpy.ndarray, y_test set\n",
    "    '''\n",
    "    \n",
    "\n",
    "    # Create a list of users\n",
    "    user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "    # Number of users to be used for the test set\n",
    "    num_user_test = 3\n",
    "    num_of_iterations = 4\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    X_test_best = None\n",
    "    y_test_best = None\n",
    "\n",
    "    all_acc_val = []\n",
    "    all_prec_val = []\n",
    "\n",
    "    # Evaluation dict\n",
    "    #TODO add recall and f1 score\n",
    "    eval_dict = {'train': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []},\n",
    "                 'test': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []}}\n",
    "\n",
    "    describe_model = True\n",
    "\n",
    "    for i in range(num_of_iterations):\n",
    "\n",
    "        print('*'*50)\n",
    "        print(f'CV Run: {i}')\n",
    "\n",
    "        # Split the data into train and test set\n",
    "        X_train_cv_pn, y_train_cv_pn, X_test_cv_pn, y_test_cv_pn, user_list = custom_cv_approach_point_clouds(np_batches, df_raw, user_list, num_user_test=num_user_test)\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_cv_pn = scaler.fit_transform(X_train_cv_pn.reshape(-1, X_train_cv_pn.shape[-1])).reshape(X_train_cv_pn.shape)\n",
    "        X_test_cv_pn = scaler.transform(X_test_cv_pn.reshape(-1, X_test_cv_pn.shape[-1])).reshape(X_test_cv_pn.shape)\n",
    "        # Before one hot encoding, class has to start at 0\n",
    "        y_train_cv_pn = y_train_cv_pn-1\n",
    "        y_test_cv_pn = y_test_cv_pn-1\n",
    "        # y label to one hot encode\n",
    "        y_train_cv_pn = to_categorical(y_train_cv_pn)\n",
    "        y_test_cv_pn = to_categorical(y_test_cv_pn)\n",
    "\n",
    "        # Build model\n",
    "        print('X_train.shape: ', X_train_cv_pn.shape)\n",
    "        print('Sample input shape: ', X_train_cv_pn[0].shape)\n",
    "        print('Sample input: ', X_train_cv_pn[0])\n",
    "        print('y_train.shape: ', y_train_cv_pn.shape)\n",
    "        \n",
    "        max_num_points = 10\n",
    "        #TODO add hyperparams\n",
    "        pointnet_model = build_pointnet(max_num_points, y_train_cv_pn.shape[1])\n",
    "\n",
    "        # Only print the model summary once\n",
    "        if describe_model:\n",
    "            pointnet_model.summary()\n",
    "            describe_model = False\n",
    "\n",
    "        # Create callback\n",
    "        #early_stop_callback = keras.callbacks.EarlyStopping(monitor=\"val_categorical_accuracy\", min_delta=1e-4, patience=5, verbose=1)\n",
    "        checkpoint_callback = keras.callbacks.ModelCheckpoint(f'model/single_run/{name}_cv{i}.h5', save_best_only=True)\n",
    "        \n",
    "        pointnet_model.compile(\n",
    "            loss=hyperparams['loss'],\n",
    "            optimizer=hyperparams['optimizer'],\n",
    "            metrics=hyperparams['metrics'],\n",
    "            )\n",
    "\n",
    "        # Train the model\n",
    "        history = pointnet_model.fit(X_train_cv_pn, \n",
    "                                y_train_cv_pn, \n",
    "                                epochs=hyperparams['num_epochs'], \n",
    "                                batch_size= hyperparams['batch_size'],\n",
    "                                validation_data=(X_test_cv_pn, y_test_cv_pn),\n",
    "                                verbose=0,\n",
    "                                shuffle=True,\n",
    "                                callbacks=[TqdmCallback(verbose=0), checkpoint_callback])\n",
    "\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "\n",
    "        # Save the history\n",
    "        save_history(hist, f'{name}_cv{i}')\n",
    "\n",
    "        #Evaluating the training performance:\n",
    "        train_loss, train_acc, train_precision, train_recall = pointnet_model.evaluate(x=X_train_cv_pn, y=y_train_cv_pn, batch_size=hyperparams['batch_size'], verbose=1)\n",
    "        f1_score_train = calc_f1_score_mlp(pointnet_model, X_train_cv_pn, y_train_cv_pn)\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'train', train_acc, train_precision, train_recall, f1_score_train)\n",
    "        print('-'*70)\n",
    "        print('Evaluation of training Data: \\n', 'training loss: ', train_loss, 'training accuracy: ', train_acc)\n",
    "\n",
    "        #Evaluating the CV pperformance:\n",
    "        val_loss, val_acc, val_precision, val_recall = pointnet_model.evaluate(x=X_test_cv_pn, y=y_test_cv_pn, batch_size=hyperparams['batch_size'], verbose=1)\n",
    "        f1_score_test = calc_f1_score_mlp(pointnet_model, X_test_cv_pn, y_test_cv_pn)\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'train', val_acc, val_precision, val_recall, f1_score_test)\n",
    "        all_acc_val.append(val_acc)\n",
    "        all_prec_val.append(val_precision)\n",
    "        print('Evaluation of validation Data: \\n', 'cv loss: ', val_loss, 'cv accuracy: ', val_acc)\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_model = pointnet_model\n",
    "            best_acc = val_acc\n",
    "            X_test_best = X_test_cv_pn\n",
    "            y_test_best = y_test_cv_pn\n",
    "\n",
    "    #Lets see the overall score as average of the scores of all the folds:\n",
    "    print('-'*70)\n",
    "    print('(all CV runs combined)')\n",
    "    print('Mean Accuracy  for the validation dataset: ', np.mean(all_acc_val))\n",
    "    print('Mean Precision for the validation dataset: ', np.mean(all_prec_val))\n",
    "    print('-'*70)\n",
    "\n",
    "    # Save the model\n",
    "    best_model.save(f'model/single_run/{name}_best_model.h5')\n",
    "\n",
    "    # Save the evaluation dict\n",
    "    save_eval_dict_pkl(eval_dict, f'{name}_eval_dict')\n",
    "\n",
    "    # Plot the learning curves\n",
    "    plot_learning_curves(hist, hyperparams, name)\n",
    "\n",
    "    return best_model, best_acc, X_test_best, y_test_best, eval_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row of data (multiple data points) got stored as single dataframe where each row is one single data point\n",
    "# Convert the dataframe to 3D numpy Matrix \n",
    "np_batches = np.array(list(map(pd.DataFrame.to_numpy, concat_batches)))\n",
    "np_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a206d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to reshape the data to be able to normalize it\n",
    "# EXAMPLE: for 2 batches (for the real data we will do it in the training loop)\n",
    "print(np_batches[0:2].shape)\n",
    "reshaped = np_batches[0:2].reshape(-1, np_batches[0].shape[-1])\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "#TODO set number of epochs to 15\n",
    "# TODO have a look what \"sparse_categorical_crossentropy\" is\n",
    "hyperparams = {'num_epochs': 10,\n",
    "               'batch_size':10,\n",
    "               'hidden_layer':2,\n",
    "               'units_hidden_layer': 32,\n",
    "               'activation_hidden': 'relu',\n",
    "               'activation_output': 'softmax',\n",
    "               'loss': 'categorical_crossentropy',\n",
    "               'metrics': ['categorical_accuracy', 'Precision', tf.keras.metrics.Recall()],\n",
    "               'optimizer': keras.optimizers.legacy.Adam(learning_rate=0.00005), #OG 0.001\n",
    "               'initialization': '-',\n",
    "               'weight regularisation l2': '-',\n",
    "               'dropout': '-',  # typically between 0.3 and 0.5 (half of weights get 0)\n",
    "               'early Stopping': 'False'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO have a look what is point 0 X0, Y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "name = 'pointnet_base'\n",
    "best_model, best_acc, X_test_best, y_test_best, eval_dict_pn = train_k_pn_model(name, np_batches, df_raw, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_learning_curves(name, {'test': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf15363",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict_pn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74842476",
   "metadata": {},
   "source": [
    "### Conclusion Testing Phase II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b398fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results\n",
    "plot_model_comparison(df_results)\n",
    "best_score = df_results.iloc[df_results['Accuracy'].idxmax()]\n",
    "print('**Model with highest accuracy score**')\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d93751-254a-4e14-8206-57c62006cc1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Testing Phase III: Model Regularization and Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1521b643",
   "metadata": {},
   "source": [
    "In this section we try to fine tune the model to achieve a better performance. We have already partially applied regularization methods in \"Testing Phase II\", but they were only used there to merely stabilize the training process. It would probably have been possible to achieve a stable training process (\"good\" loss curve) without regularization. But the bug fixxing was more an iterative process in which different error sources etc. should be excluded.\n",
    "\n",
    "In this section we focus on the fine tuning of these regularization methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d3e95e-fdd2-4ee3-a262-bf72ea5f7bb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "In a first step we will tune the model by hand. This is followed by a randomized search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79e8bc",
   "metadata": {},
   "source": [
    "we will focus on following hyperparameter\n",
    "* number of neurons\n",
    "* regularization\n",
    "* number of layers\n",
    "* activation function\n",
    "* dropout\n",
    "* Initialization\n",
    "* Optimizer\n",
    "* Batch Size\n",
    "* Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe03ed-1008-4e05-81f7-970f38eac33a",
   "metadata": {},
   "source": [
    "## Manual Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54063b50-5e46-49f7-b525-7df57884abb7",
   "metadata": {},
   "source": [
    "Keeping in mind that the model with extracted features achieved a higher perfomance we will focus on this data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3df217-eefe-4187-8713-9e17c5c978bc",
   "metadata": {},
   "source": [
    "In this section we start using EarlyStopping and LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6112e2-85aa-4980-bcad-684b00de671d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hyperparams = {'num_epochs': 55,\n",
    "               'batch_size': 32,\n",
    "               'hidden_layer': 3,\n",
    "               'units_hidden_layer': [16, 16, 8],#[64, 64, 32, 16],\n",
    "               'activation_hidden': keras.layers.LeakyReLU(alpha=0.1), #'LeakyReLU' #'relu',\n",
    "               'activation_output': 'softmax',\n",
    "               'loss': 'categorical_crossentropy',\n",
    "               'metrics': ['categorical_accuracy', 'Precision', tf.keras.metrics.Recall()],\n",
    "               'optimizer': keras.optimizers.SGD(lr=0.001, momentum=0.9) #keras.optimizers.legacy.Adam(learning_rate=0.0001), #0.0003\n",
    "               'kernel_initializer': 'he_normal', # used for ReLU activation function\n",
    "               'bias_initializer': 'zeros',\n",
    "               'initialization': '-',\n",
    "               'weight regularisation l1': '',\n",
    "               'weight regularisation l2': 0.001,\n",
    "               'dropout': 0.5,  # typically between 0.3 and 0.5 (half of weights get 0)\n",
    "               'early Stopping': 'False',\n",
    "               'reduce_lr': True} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cac05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO run with hiher l2 norm 18.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ce74d-e908-41b4-b764-beadbefc32bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'mlp_base_model_extracted_tuned'\n",
    "df = df_aggregate\n",
    "best_model, best_acc, X_test_best, y_test_best, eval_dict = train_k_mlp_model(name, df, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d08c0-d4ef-4b51-83a7-665b27807d78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_multiple_learning_curves(name, {'test': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89572ec-f04a-40a5-9b4c-17cb6ca23125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_multiple_acc_curves(name, {'test': 'test'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72e28def",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30ebd80c",
   "metadata": {},
   "source": [
    "Manual fine tuning of the model is a highly iterative process. Instead of cluttering the entire notebook with multiple trial runs and making it confusing, I will describe the iterative process here. The actual changes were modified directly in the hyperparameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46b713ed",
   "metadata": {},
   "source": [
    "For example, we see here that the learning rate is too low. One could reach the goal with a low learning rate, but this wastes computing resources unnecessarily, because we need more epochs.\n",
    "I decide to increase the learning rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bc2e19a",
   "metadata": {},
   "source": [
    "![title](img/lr_too_low.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efbcae6d",
   "metadata": {},
   "source": [
    "I also figured out that reducing the learning rate after some time can help the model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = load_history('impact_lr_scheduler')\n",
    "plot_learning_curves(hist, {'None': None}, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f922a2f-bcb6-40c5-be7f-fef02fdd6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert impact_lr_scheduler.h5 learning curve\n",
    "\n",
    "# reducing the learning rate after some time can help the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc076c65-a435-4042-afd6-c47b82a672b6",
   "metadata": {},
   "source": [
    "#### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9c854-930f-4024-9582-c38642b879ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot best_model_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273ea14-64d3-4c12-84e9-52f479faa4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used hyperparamter\n",
    "'''\n",
    "# Hyperparameters\n",
    "hyperparams = {'num_epochs': 50,\n",
    "               'batch_size': 32,\n",
    "               'hidden_layer': 3,\n",
    "               'units_hidden_layer': [16, 16, 8],#[64, 64, 32, 16],\n",
    "               'activation_hidden': keras.layers.LeakyReLU(alpha=0.1), #'LeakyReLU' #'relu',\n",
    "               'activation_output': 'softmax',\n",
    "               'loss': 'categorical_crossentropy',\n",
    "               'metrics': ['categorical_accuracy', 'Precision', tf.keras.metrics.Recall()],\n",
    "               'optimizer': keras.optimizers.legacy.Adam(learning_rate=0.0001), #0.0003\n",
    "               'kernel_initializer': 'he_normal', # used for ReLU activation function\n",
    "               'bias_initializer': 'zeros',\n",
    "               'initialization': '-',\n",
    "               'weight regularisation l1': '',\n",
    "               'weight regularisation l2': 0.001,\n",
    "               'dropout': 0.5,  # typically between 0.3 and 0.5 (half of weights get 0)\n",
    "               'early Stopping': 'False',\n",
    "               'reduce_lr': True} \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a770ea-9994-4621-8833-fcaa612326a9",
   "metadata": {},
   "source": [
    "loss=0.554, categorical_accuracy=0.786, precision=0.844, recall_2=0.722, val_loss=0.431, val_categorical_accuracy=0.897, val_precision=0.898, val_recall_2=0.896]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a074907",
   "metadata": {},
   "source": [
    "## Automatic hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2096d7-3187-4a90-b6dd-e649eb95a501",
   "metadata": {},
   "source": [
    "To find a good value range for a specific hyperparamter, simply have a look online <br>\n",
    "e.g. https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/\n",
    "for L2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9928671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "\n",
    "class Classification_MLP_tuner(HyperModel):\n",
    "    '''\n",
    "    Build a HyperParameter Model with variable hyperparameters\n",
    "    e.g. Optimizer, learning rate \n",
    "    \n",
    "    Note: model.compile must be included in this function\n",
    "    '''\n",
    "\n",
    "    def __init__(self, name:str, input_shape, num_output, learning_rate:list, max_num_of_hidd_layer:int, max_num_of_neuron_per_layer:int, min_num_of_neuron_per_layer:int, activation_func_hidden_layer:list, weight_regularisation_l1:list, weight_regularisation_l2:list):\n",
    "        self.name = name\n",
    "        self.input_shape = input_shape\n",
    "        self.num_ouput = num_output\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_num_of_hidd_layer = max_num_of_hidd_layer\n",
    "        self.max_num_of_neuron_per_layer = max_num_of_neuron_per_layer\n",
    "        self.min_num_of_neuron_per_layer = min_num_of_neuron_per_layer\n",
    "        self.activation_func_hidden_layer = activation_func_hidden_layer\n",
    "        self.weight_regularisation_l1 = weight_regularisation_l1\n",
    "        self.weight_regularisation_l2 = weight_regularisation_l2\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        model = keras.Sequential(name=self.name)\n",
    "        model.add(layers.InputLayer(input_shape=self.input_shape))\n",
    "        \n",
    "        l1 = hp.Float('l1',\n",
    "                 min_value=self.weight_regularisation_l1[0],\n",
    "                 max_value=self.weight_regularisation_l1[1],\n",
    "                 sampling='LOG',\n",
    "                default=0)\n",
    "        \n",
    "        l2 = hp.Float('l2',\n",
    "                 min_value=self.weight_regularisation_l2[0],\n",
    "                 max_value=self.weight_regularisation_l2[1],\n",
    "                 sampling='LOG',\n",
    "                default=0)\n",
    "\n",
    "        # Use l1, l2 regularization?\n",
    "        if l1 and l2:\n",
    "            kernel_regu = keras.regularizers.L1L2(l1=l1, l2=l2)\n",
    "        elif l1:\n",
    "            kernel_regu = keras.regularizers.L1(l1=l1)\n",
    "        elif l2:\n",
    "            kernel_regu = keras.regularizers.L2(l2=l2)\n",
    "        else: # Do not use regularization\n",
    "            kernel_regu = None\n",
    "            \n",
    "        # Choose activation function\n",
    "        hp_activation = hp.Choice('dense_activation', values=self.activation_func_hidden_layer)\n",
    "        if hp_activation == 'leaky_relu': # Leaky Relu does not have an alias in keras and the values list for choice can onl contain one type\n",
    "            hp_activation = keras.layers.LeakyReLU(alpha=0.1)\n",
    "            \n",
    "        for i in range(hp.Int('num_layers', 2, self.max_num_of_hidd_layer)):\n",
    "            model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                min_value=self.min_num_of_neuron_per_layer,\n",
    "                                                max_value=self.max_num_of_neuron_per_layer,\n",
    "                                                step=2),\n",
    "                                    activation=hp_activation,\n",
    "                                    kernel_initializer='he_normal',\n",
    "                                    bias_initializer='zeros',\n",
    "                                    kernel_regularizer=kernel_regu ))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Dropout(rate=hp.Choice(\n",
    "                                            'dropout_rate',\n",
    "                                            values=[0.3, 0.4, 0.5]\n",
    "                                            )))\n",
    "        model.add(layers.Dense(5, activation='softmax')) #TODO output variable\n",
    "\n",
    "        #Compile\n",
    "        opt = keras.optimizers.Adam(hp.Float(\n",
    "                                'learning_rate',\n",
    "                                min_value=self.learning_rate[0],\n",
    "                                max_value=self.learning_rate[1],\n",
    "                                sampling='LOG',\n",
    "                                default=1e-3)\n",
    "                                )\n",
    "        metrics = [keras.metrics.CategoricalAccuracy()]\n",
    "        loss_func = keras.losses.CategoricalCrossentropy()\n",
    "        model.compile(loss=loss_func, optimizer=opt, metrics=metrics)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacffca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mlp_hyperparameter_search(df, max_trials:int, epochs:int, batch_size:int, load_search:Optional[str]=None):\n",
    "    '''\n",
    "    Suche nach den besten Hyperparametern des MLP\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_trials :\n",
    "        maximum number of random models to investigate\n",
    "    epochs :\n",
    "        number of iterations to train neural network\n",
    "    batch_size :\n",
    "        Anzahl der Samples fuer die Gradient berechnet wird (somit gemittelt)\n",
    "    '''\n",
    "\n",
    "    # Create a list of users\n",
    "    user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "    # Number of users to be used for the test set\n",
    "    num_user_test = 3\n",
    "    \n",
    "    #create folder\n",
    "    search_path = join('model/hp_search', 'mlp')\n",
    "\n",
    "    #Convert input data\n",
    "    X_train, y_train, X_test, y_test, user_list = custom_cv_approach(df, user_list, num_user_test=num_user_test)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # Before one hot encoding, class has to start at 0\n",
    "    y_train = y_train-1\n",
    "    y_test = y_test-1\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    #Transform to Dataset\n",
    "    X_train_stream_labeled = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    X_test_stream_labeled = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    # Shuffle Data\n",
    "    X_train_stream_labeled = X_train_stream_labeled.shuffle(buffer_size=df.shape[0])\n",
    "    X_test_stream_labeled = X_test_stream_labeled.shuffle(buffer_size=df.shape[0])\n",
    "    #create batches\n",
    "    X_train_stream_labeled = X_train_stream_labeled.batch(batch_size)\n",
    "    X_test_stream_labeled = X_test_stream_labeled.batch(batch_size)\n",
    "\n",
    "    #build model\n",
    "    input_shape = (X_train.shape[1], )\n",
    "    output_shape = len(np.unique(y_train))\n",
    "    \n",
    "    #TODO write them in hyper param dict\n",
    "    hyperparams_search = {'activation_func_hidden_layer': ['relu', 'leaky_relu', 'elu'], #['tanh', 'sigmoid', 'elu', 'relu']\n",
    "                       'min_num_of_neuron_per_layer': 2,\n",
    "                       'max_num_of_neuron_per_layer': 16,\n",
    "                       'max_num_of_hidd_layer': 5,\n",
    "                       'learning_rate': [5e-5, 5e-3],\n",
    "                          'weight_regularisation_l1': [0.000001, 0.1],\n",
    "                          'weight_regularisation_l2': [0.000001, 0.1]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    mlp_model = Classification_MLP_tuner('mlp', input_shape,\n",
    "                                         output_shape, learning_rate=hyperparams_search['learning_rate'],\n",
    "                                         max_num_of_hidd_layer=hyperparams_search['max_num_of_hidd_layer'], \n",
    "                                         max_num_of_neuron_per_layer=hyperparams_search['max_num_of_neuron_per_layer'], \n",
    "                                         min_num_of_neuron_per_layer=hyperparams_search['min_num_of_neuron_per_layer'], \n",
    "                                         activation_func_hidden_layer=hyperparams_search['activation_func_hidden_layer'],\n",
    "                                        weight_regularisation_l1 = hyperparams_search['weight_regularisation_l1'],\n",
    "                                        weight_regularisation_l2 = hyperparams_search['weight_regularisation_l2'])\n",
    "    \n",
    "    #REGULARIZATION\n",
    "    early_stop_callback = keras.callbacks.EarlyStopping(monitor=\"val_categorical_accuracy\", min_delta=1e-3, patience=5, verbose=1)\n",
    "    #reduce_lr_callback = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.2,\n",
    "    #                                       patience=5, min_lr=0.00001,\n",
    "    #                                       min_delta=0.001)\n",
    "    \n",
    "    callbacks = [early_stop_callback]\n",
    "\n",
    "    # Create name with timestamp\n",
    "    t = time.localtime()\n",
    "    timestamp = time.strftime('%b-%d-%Y_%H%M', t)\n",
    "\n",
    "    #train\n",
    "    if load_search is None:\n",
    "        tuner_search = keras_tuner.RandomSearch(mlp_model, objective='val_categorical_accuracy', max_trials=max_trials, project_name=join(search_path, f'prj_{timestamp}_mlp'))\n",
    "        tuner_search.search(X_train_stream_labeled, \n",
    "                            epochs=epochs, \n",
    "                            validation_data=X_test_stream_labeled,\n",
    "                            callbacks=callbacks)\n",
    "\n",
    "        # Not required anymore, search can be easily restored from search path!\n",
    "        '''\n",
    "        pickle_path = join(search_path, f'mlp_search_{timestamp}.pkl')\n",
    "        with open(pickle_path, 'wb') as handle:\n",
    "            pickle.dump(tuner_search, handle)\n",
    "        '''\n",
    "    else:\n",
    "        tuner_search = keras_tuner.RandomSearch(mlp_model, objective='val_categorical_accuracy', max_trials=max_trials, overwrite=False, project_name=load_search)\n",
    "        return tuner_search\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6284fb8",
   "metadata": {},
   "source": [
    "There are different hyperparameter we want to analyze the impact of:\n",
    "* Number of layers\n",
    "* Number of nodes\n",
    "* Activation function\n",
    "* Optimizer\n",
    "* Learning rate\n",
    "* Number of epochs -> we will use an Early stopping Callback\n",
    "* Batch size\n",
    "* Adding weight regularization\n",
    "* Adding dropout\n",
    "\n",
    "Due to the amount of hyperparameter combination:<br>\n",
    "a univariate hyperparemeter search is not target-oriented, because the parameters influence each other.\n",
    "we have a multivariate problem. The number of possible value combinations, however, cannot (at least with the hardware available to me) all be examined. A possible approach is to randomly select parameter sets, i.e. to perform a random search.\n",
    "\n",
    "Procedure:\n",
    "* for number of examined hyperparmeter sets (e.g. here 150)\n",
    "    * Define hyperparameter space (some parameters continuous, others discrete)\n",
    "    * draw random combination of values\n",
    "    * for #CV_folds:\n",
    "        * select n users for validation set\n",
    "        * use rest for training with the randomly drawn hyperparameter combination\n",
    "\n",
    "Finally, analyze which hyperparmeter combination has the best validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0916ce",
   "metadata": {},
   "source": [
    "First perform a random search in hyperparameter space with the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOOD write all hyperparameter options in one dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071f9a2f-f64f-4e88-8aeb-8079160fe160",
   "metadata": {},
   "source": [
    "Reference time: 3h 3min to try 150 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6d46a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp_hyperparameter_search(df_raw, max_trials=150, epochs=35, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a2f67",
   "metadata": {},
   "source": [
    "We should always make sure that we can restore or load important evvaluation data, whole models or search results.<br>\n",
    "Coming back after 2 days of random hyperparameter search only to find out that the kernel crashed or restarted at any point in time is suboptimal<br>\n",
    "Simply relying on the fact that the jupyter kernel will store the python objects is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34fc5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_path = '/home/josh/dde1_hand_motion/model/hp_search/mlp/prj_Mar-09-2023_2332_mlp_raw' #'/home/josh/dde1_hand_motion/model/hp_search/mlp/prj_Mar-16-2023_1415_mlp'\n",
    "load_model = True\n",
    "\n",
    "if load_model:\n",
    "    print('*'*50)\n",
    "    print('Reload tuner search')\n",
    "    tuner_search = mlp_hyperparameter_search(df_raw, max_trials=1, epochs=1, batch_size=10, load_search = project_path)\n",
    "    print(tuner_search.get_best_hyperparameters(4))\n",
    "    print(tuner_search.results_summary(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd33042",
   "metadata": {},
   "source": [
    "Now perform the same search with the extracted data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28618180",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_hyperparameter_search(df_aggregate, max_trials=150, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc4cbe",
   "metadata": {},
   "source": [
    "As I said before:<br>\n",
    "always store the search object, in case we have to restore it after the kernel crashed. <br>\n",
    "Here we can simply load the Search Object where we used the extracted features (even if we come back after several days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '/home/josh/dde1_hand_motion/model/hp_search/mlp/prj_Mar-11-2023_0019_mlp_extract'\n",
    "load_model = False\n",
    "\n",
    "if load_model:\n",
    "    tuner_search = mlp_hyperparameter_search(df_raw, max_trials=1, epochs=1, batch_size=10, load_search = project_path)\n",
    "    print(tuner_search.get_best_hyperparameters(4))\n",
    "    print(tuner_search.results_summary(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f7c2b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231639e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_search_info(pkl_path:str, num_of_model:int):\n",
    "\n",
    "    if os.path.getsize(pkl_path) > 0:\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            rand_search = pickle.load(f)\n",
    "    else:\n",
    "        print('File is empty!')\n",
    "        return\n",
    "\n",
    "    print('best parameter:', rand_search.best_params_)\n",
    "    print('best score:', rand_search.best_score_)\n",
    "\n",
    "    search_df = pd.DataFrame(rand_search.cv_results_)\n",
    "    search_df.set_index('rank_test_score', inplace=True)\n",
    "    \n",
    "    for model_rank in range(1, num_of_model+1):\n",
    "        print(f'\\n###{model_rank}_model###')\n",
    "\n",
    "        try:\n",
    "            params_n_model = search_df['params'][model_rank]\n",
    "            score_n_model = search_df['split0_test_score'][model_rank]\n",
    "        except KeyError:\n",
    "            print(f'no model with rank {model_rank} (previous is multiple')\n",
    "            continue\n",
    "        print(params_n_model)\n",
    "        print(score_n_model)\n",
    "    \n",
    "    return rand_search.best_score_, rand_search.best_params_\n",
    "\n",
    "\n",
    "def keras_tuner_search_results(pkl_path:str):\n",
    "    \n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        rand_search = pickle.load(f)\n",
    "\n",
    "    result_summary = rand_search.results_summary()\n",
    "    print(result_summary)\n",
    "    best_model = rand_search.get_best_models(num_models=1)[0]\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96eb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pickle\n",
    "import os\n",
    "search_path = 'model/hp_search/mlp/mlp_search_Mar-09-2023_2332.pkl'\n",
    "keras_tuner_search_results(search_path)\n",
    "rand_search_info(search_path, num_of_model=10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b9440",
   "metadata": {},
   "source": [
    "## PointNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9113c",
   "metadata": {},
   "source": [
    "# 6. Evaluation of the model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120227c-6716-4d32-9f35-5c66e81b9efd",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  All Models/Overall Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856f41d-c408-4ea5-9a61-5d4b09fe41cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. Lessons Learnt and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60002ae0",
   "metadata": {},
   "source": [
    "tell us what you found and what you learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e21ae-ecd5-407c-9780-ed5ae5fd8371",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "\n",
    "Gradient Descent\n",
    "\n",
    "Random Forests\n",
    "\n",
    "Boosting (LightGBM)\n",
    "https://lightgbm.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a301e0-6c8d-4cbb-a351-3172541c270b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d86898-22d2-41d8-9bfb-424eb0bbffc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f84c7-3d1c-47b1-9cc2-826b82d14bc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be58b0d-4ccb-44b8-b4d4-775cf717f2bc",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "PR Curve\n",
    "ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96099216-ad7d-4b34-95f0-78142fd66381",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81443258-bf9e-4898-a68d-3f2793d3fb51",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6e58a-1ec3-4c67-a9d3-ecb525c9855f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092be0a4-a71d-4c7a-8a63-85877163de51",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c53728-5edd-4dbf-9019-9718a117ff10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "a71aa70298631feedc494dbad6cb00b706fca5b11f5a9d39eafcd631df241c69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
