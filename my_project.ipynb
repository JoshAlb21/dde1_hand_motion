{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42d71b5-2572-4d35-8576-a420e5a95235",
   "metadata": {},
   "source": [
    "This notebooks uses the following dataset <br>\n",
    "https://archive.ics.uci.edu/ml/datasets/Motion+Capture+Hand+Postures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5135214-99c1-4a37-a8bd-f599f715d139",
   "metadata": {},
   "source": [
    "# 1. Analysis of the Problem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70eef1-e2d1-4b29-8546-bb140730fdc1",
   "metadata": {},
   "source": [
    "## Understand the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b0709",
   "metadata": {},
   "source": [
    "working hypothesis\n",
    "think about model architecture\n",
    "loss function\n",
    "and loss criteria\n",
    "\n",
    "select a measure of success\n",
    "    Detect all classes/types of hand gestures with a high accuracy\n",
    "    Classification Problem\n",
    "    Check whether class-imbalanced problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed71874",
   "metadata": {},
   "source": [
    "Dataset with class of the hand gesture/'Class' (our target value) the person which performed the hand gesture ('User') and a \n",
    "feature vector that consists 11 subvectors. Each subvector contains X, Y and Z coordinates. Those coordinates belong to one of the detected markes on the hand glove the user is wearing\n",
    "\n",
    "* motion capture camera records 12 users performing 5 hand postures with markers attached to a left-handed glove\n",
    "* rigid pattern of markers on the back of the glove -> establish local coordinate system for the hand\n",
    "* 11 markers were attached to the thumb and fingers of the glove\n",
    "* there is no a priori correspondence between the markers of two given records\n",
    "* due to the resolution of the capture volume and self-occlusion due to the orientation and configuration of the hand and fingers, many records have missing markers.\n",
    "    -> the number of visible markers in a record varied considerably.\n",
    "\n",
    "\n",
    "The Problem:\n",
    "We cannot easily apply traditional approaches because of two properties of point clouds:\n",
    "* unordered collection (Point 1 with X,Y and Z coordinates could refer to the thh )\n",
    "* the size of the point cloud varies (due to occlusion, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c869c7",
   "metadata": {},
   "source": [
    "## Useful Information from the authors/paper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23d0019a",
   "metadata": {},
   "source": [
    "Class label:<br>\n",
    "1=Fist(with thumb out), 2=Stop(hand flat), 3=Point1(point with pointer finger), 4=Point2(point with pointer and middle fingers), 5=Grab(fingers curled as if to grab)\n",
    "\n",
    "\n",
    "Preprocessing:<br>\n",
    "all markers were transformed to the local coordinate system of the record containing them.\n",
    "\n",
    "Reduce number of records:<br>\n",
    "each transformed marker with a norm greater than 200 millimeters was pruned. \n",
    "records that contained fewer than 3 markers was removed. \n",
    "the data has at most 12 markers per record and at least 3\n",
    "\n",
    "Be careful:<br>\n",
    "It is likely that for a given record and user there exists a near duplicate record originating from the same user.\n",
    "-> evaluate on leave-one-user-out basis wherein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effceef9",
   "metadata": {},
   "source": [
    "## Ideas I want to try out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6f4c635",
   "metadata": {},
   "source": [
    "\n",
    "**My goal**\n",
    "\n",
    "* able to predict which gesture a person is performing\n",
    "\n",
    "* achieve a high accuracy\n",
    "\n",
    "**My idea/approach**\n",
    "\n",
    "* 1.approach: extract features that are meaningful for a given data point, train conventional models\n",
    "\n",
    "* 2.approach: use models that are adapted to point clouds and have been developed specifically for this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ff76df",
   "metadata": {},
   "source": [
    "# 2. Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621bcfc",
   "metadata": {},
   "source": [
    "Check for missing values, NaN values or features,\n",
    "uniqueness of the data (is it as it was expected to be)\n",
    "understand the variations in the data (statistical tools)\n",
    "outliers?\n",
    "Is it possible to combine features?\n",
    "Do you have unnecessary features? (a column which gives no information – for instance name\n",
    "column– or a feature you consider unrelated to the problem)\n",
    "Check the correlation matrix. It will tell you how much the features are related. You may say,\n",
    "for instance, there is a great potential to reduce number of dimensions.\n",
    "scale data (for example, in the [-1, 1] range)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e1faa-b515-472d-8b78-a5489e1d1003",
   "metadata": {},
   "source": [
    "## Preparing the enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbe7a7-59b4-4e40-badd-440f2348011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reload_ext autoreload\n",
    "#%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "import time\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner\n",
    "from tensorflow.keras import layers\n",
    "from typing import Tuple, Optional, Callable\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# My custom functions\n",
    "from scripts import analyze_helper, visualisation\n",
    "\n",
    "# Utility functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, precision_recall_curve, average_precision_score, recall_score, f1_score, accuracy_score, precision_score\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from os.path import dirname, abspath, join\n",
    "\n",
    "# Models we want to use\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80ae7bb3",
   "metadata": {},
   "source": [
    "## Write utility functions I want to use multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm(y_true, y_pred):\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    class_labels = ['Fist', 'Stop', 'Point1', 'Point2', 'Grab']\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred, labels=[1, 2, 3, 4, 5])\n",
    "    \n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "    #normalize\n",
    "    cf_matrix = (cf_matrix.T/cf_matrix.sum(axis=1)).T\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten()]\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(5,5)\n",
    "\n",
    "    custom_cmap = sns.light_palette(\"#009682\", as_cmap=True)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap=custom_cmap, xticklabels=class_labels, yticklabels=class_labels, cbar=False)\n",
    "    plt.ylabel('true label')\n",
    "    plt.xlabel('predicted label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report:\n",
    "\n",
    "    report: dict\n",
    "\n",
    "    def __init__(self, model_name:str, model, X_test, y_test, description:list=[]):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.description = description\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.report = self.create_report(model)\n",
    "\n",
    "\n",
    "    def create_report(self, model):\n",
    "\n",
    "        try:\n",
    "            if type(model) == keras.Sequential:\n",
    "                y_score = model.predict(self.X_test)\n",
    "            else:\n",
    "                y_score = model.predict_proba(self.X_test)\n",
    "        except AttributeError:\n",
    "            print('No report possible, because no predict_proba method')\n",
    "            report = None\n",
    "            return\n",
    "        y_score_2 = model.predict(self.X_test)\n",
    "        print(y_score.shape)\n",
    "        print(y_score_2.shape)\n",
    "        print(self.y_test.shape)\n",
    "        print(self.y_test)\n",
    "        if type(model) != keras.Sequential:\n",
    "            report = classification_report(self.y_test, y_score_2, output_dict=True)\n",
    "        else:\n",
    "            y_score_2 = to_categorical(np.argmax(y_score_2, axis=1))\n",
    "            print(y_score_2.shape)\n",
    "            print(self.y_test.shape)\n",
    "            report = classification_report(self.y_test, y_score_2, output_dict=True)\n",
    "            #NN report does not have accuracy score -> have a look why\n",
    "            accuracy = accuracy_score(self.y_test, y_score_2)\n",
    "            report['accuracy'] = accuracy\n",
    "\n",
    "        return report\n",
    "    \n",
    "    def get_report_as_df(self, df_to_save_to:pd.DataFrame):\n",
    "        'Get the report as a dataframe'\n",
    "\n",
    "        print(self.report)\n",
    "\n",
    "        new_row = {'model': self.model_name,\n",
    "                   'Accuracy': round(self.report[\"accuracy\"],6), \n",
    "                   'Precision': round(self.report[\"macro avg\"][\"precision\"],5),\n",
    "                   'Recall': round(self.report[\"macro avg\"][\"recall\"],6),\n",
    "                   'F1_score': round(self.report[\"macro avg\"][\"f1-score\"],6)} \n",
    "        df_to_save_to = df_to_save_to.append(new_row, ignore_index=True)\n",
    "\n",
    "        return df_to_save_to\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        if self.report is None:\n",
    "            print('No return possbile')\n",
    "            return 'No valid return'\n",
    "\n",
    "        pattern = '''\n",
    "        ***********************REPORT*******************************\n",
    "        Average (macro) precision: {}\n",
    "        Average accuracy: {}\n",
    "        Average (macro) recall: {}\n",
    "        Average (macro) f1-score: {}\n",
    "        Description {}\n",
    "        ************************************************************\n",
    "        '''\n",
    "        return pattern.format(round(self.report[\"macro avg\"][\"precision\"],5), round(self.report[\"accuracy\"],6), round(self.report[\"macro avg\"][\"recall\"],6), round(self.report[\"macro avg\"][\"f1-score\"],6), ', '.join(self.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5843a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_eval_dict_pkl(eval_dict, name):\n",
    "\n",
    "    # Get path to save the history\n",
    "    eval_folder = 'model/single_run/eval'\n",
    "    model_path = join(eval_folder, name)\n",
    "    \n",
    "    with open(model_path, 'wb') as file_pi:\n",
    "        pickle.dump(eval_dict, file_pi)\n",
    "\n",
    "def load_eval_dict_pkl(name) -> dict:\n",
    "\n",
    "    # Get path to save the history\n",
    "    eval_folder = 'model/single_run/eval'\n",
    "    model_path = join(eval_folder, name)\n",
    "\n",
    "    with open(model_path, 'rb') as file_pi:\n",
    "        eval_dict = pickle.load(file_pi)\n",
    "    \n",
    "    return eval_dict\n",
    "\n",
    "def save_to_eval_dict(eval_dict:dict, split_set:str, acc:float, precission:float, recall:float, f1:float):\n",
    "    ''' Save multiple metrics to a dictionary for evaluation '''\n",
    "\n",
    "    if split_set not in ['train', 'test']:\n",
    "        raise ValueError('split_set must be either train or test')\n",
    "    \n",
    "    eval_dict[split_set]['accuracy'].append(acc)\n",
    "    eval_dict[split_set]['precision'].append(precission)\n",
    "    eval_dict[split_set]['recall'].append(recall)\n",
    "    eval_dict[split_set]['f1'].append(f1)\n",
    "\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eeeda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eval_dict_barplot_new(data):\n",
    "\n",
    "    # Extracting data\n",
    "    train_acc = data['train']['accuracy']\n",
    "    train_prec = data['train']['precision']\n",
    "    train_recall = data['train']['recall']\n",
    "    train_f1 = data['train']['f1']\n",
    "    test_acc = data['test']['accuracy']\n",
    "    test_prec = data['test']['precision']\n",
    "    test_recall = data['test']['recall']\n",
    "    test_f1 = data['test']['f1']\n",
    "\n",
    "    # Creating subplots for accuracy and precision\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 5))\n",
    "    bar_width = 0.2\n",
    "\n",
    "    # Plot for accuracy\n",
    "    axs[0][0].bar([i+bar_width/2 for i in range(len(train_acc))], train_acc, width=bar_width, color='b', label='Train Accuracy')\n",
    "    axs[0][0].bar([i-bar_width/2 for i in range(len(test_acc))], test_acc, width=bar_width, color='r', label='Test Accuracy')\n",
    "    axs[0][0].set_xticks(range(len(train_acc)))\n",
    "    axs[0][0].set_xticklabels([f'CV{i}' for i in range(len(train_acc))])\n",
    "    axs[0][0].set_ylabel('Accuracy')\n",
    "    axs[0][0].set_title('Accuracy')\n",
    "    axs[0][0].legend()\n",
    "\n",
    "    # Plot for precision\n",
    "    axs[0][1].bar([i+bar_width/2 for i in range(len(train_prec))], train_prec, width=bar_width, color='b', label='Train Precision')\n",
    "    axs[0][1].bar([i-bar_width/2 for i in range(len(test_prec))], test_prec, width=bar_width, color='r', label='Test Precision')\n",
    "    axs[0][1].set_xticks(range(len(train_acc)))\n",
    "    axs[0][1].set_xticklabels([f'CV{i}' for i in range(len(train_acc))])\n",
    "    axs[0][1].set_ylabel('Precision')\n",
    "    axs[0][1].set_title('Precision')\n",
    "    axs[0][1].legend()\n",
    "\n",
    "    # Plot for recall\n",
    "    axs[1][0].bar([i+bar_width/2 for i in range(len(train_recall))], train_recall, width=bar_width, color='b', label='Train Recall')\n",
    "    axs[1][0].bar([i-bar_width/2 for i in range(len(test_recall))], test_recall, width=bar_width, color='r', label='Test Recall')\n",
    "    axs[1][0].set_xticks(range(len(train_recall)))\n",
    "    axs[1][0].set_xticklabels([f'CV{i}' for i in range(len(train_recall))])\n",
    "    axs[1][0].set_ylabel('Recall')\n",
    "    axs[1][0].set_title('Recall')\n",
    "    axs[1][0].legend()\n",
    "\n",
    "    # Plot for f1_score\n",
    "    axs[1][1].bar([i+bar_width/2 for i in range(len(train_f1))], train_f1, width=bar_width, color='b', label='Train F1-Score')\n",
    "    axs[1][1].bar([i-bar_width/2 for i in range(len(test_f1))], test_f1, width=bar_width, color='r', label='Test F1-Score')\n",
    "    axs[1][1].set_xticks(range(len(train_f1)))\n",
    "    axs[1][1].set_xticklabels([f'CV{i}' for i in range(len(train_f1))])\n",
    "    axs[1][1].set_ylabel('F1 Score')\n",
    "    axs[1][1].set_title('F1 Score')\n",
    "    axs[1][1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dbaf5d-96bf-4e9c-baf4-905ed859f7c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07e663-c32d-4b98-9088-57c49d18b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_raw = os.path.join('data', 'Postures.csv')\n",
    "df_raw = pd.read_csv(file_path_raw, sep=',', na_values='?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30b72cb9",
   "metadata": {},
   "source": [
    "## Understand the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bce8e0c7",
   "metadata": {},
   "source": [
    "### Choose a metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4f530b1",
   "metadata": {},
   "source": [
    "To choose a metric we have to check whether the classes are balenced/unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc896a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df_raw['Class'].value_counts(sort=False)\n",
    "class_counts.plot(kind='bar', title='Gestures Class Distibution')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51b007c1",
   "metadata": {},
   "source": [
    "To jugde the model perfomance we will choose a mixture of multiple metrics:\n",
    "* Confusion Matrix\n",
    "* Accuracy (we have balanced classes!)\n",
    "* Recall (made TP predictions divided by possible TP predictions)\n",
    "* precission-recall plot\n",
    "* F1-Score (harmonic mean between recall and precision, combines the two metrics into one value)\n",
    "\n",
    "TODO \n",
    "Maybe Later\n",
    "* ROC AUC (Receiver Operator Characteristic — Area Under the Curve, we want a high TPR with a low FPR)\n",
    "Note: we will use the One vs Rest strategy for ROC AUC (because it is usally a metric for binary classification)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebe4d214",
   "metadata": {},
   "source": [
    "Write utility function to use the ROC AUC for multiclass classficiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7bb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_multiclass(model, X_test, y_test):\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    y_score = model.predict_proba(X_test)\n",
    "    y_score_2 = model.predict(X_test)\n",
    "    \n",
    "    #print('Amount and Distribution of Test Data: \\n', y_test.value_counts())\n",
    "    y_bin = pp.label_binarize(y_test, classes=model.classes_)\n",
    "\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    classes = model.classes_\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_bin[:, i], y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(y_bin[:, i], y_score[:, i])\n",
    "        #print('\\n average precision: ', classes[i], ': ', average_precision[i])\n",
    "        try:\n",
    "            plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(classes[i]))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    \n",
    "    plt.xlabel(\"recall\")\n",
    "    plt.ylabel(\"precision\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"precision vs. recall curve\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b640a001-a477-4f13-a4ec-c9f9306bf727",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1b443-1126-4ad6-9236-4d325e12dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29bafb-29a4-4f25-9d9b-86cfba219b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which columns have missing values\n",
    "print(f\"Missing values in: {analyze_helper.check_for_missing_vals(df_raw)}\")\n",
    "# Compute missing ratio, hide columns with no missing values (0.0%)\n",
    "analyze_helper.compute_missing_ratio(df_raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efc34347",
   "metadata": {},
   "source": [
    "Hint 1 for preprocessing:\n",
    "drop the coordinates (X,Y,Z) for point 10 and 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93bd9c-0bea-4be4-96f7-3d3c3b250437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3cf151-48ba-421c-8d3a-0d3f7673004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head(5)\n",
    "df_raw.drop([0], inplace=True)\n",
    "df_raw.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Instances  : ', df_raw.shape[0])\n",
    "print('Number of Attributes : ', df_raw.shape[1])\n",
    "print('Number of target classes   : ', df_raw['Class'].nunique()-1)\n",
    "print('Number of users   : ', df_raw['User'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7cb979",
   "metadata": {},
   "source": [
    "The description says the data set contains 12 User. No information provided (why are 14 user in the data?).\n",
    "Hint for us to drop User 4 and 7 ?\n",
    "They both have signifiantly less data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848511d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_group = df_raw.groupby(['User'], sort=False)\n",
    "user_group.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfdf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60989e0-5d3b-4ad2-95c6-1fbdaa290726",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084054c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltHand(handPoints):\n",
    "    plt.close('all')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    \n",
    "    for i in range(11):\n",
    "        pntx = f'X{i}'\n",
    "        pnty = f'Y{i}'\n",
    "        pntz = f'Z{i}'\n",
    "        \n",
    "        if(handPoints[pntx].values[0] == 0 or\n",
    "            handPoints[pnty].values[0] == 0 or\n",
    "            handPoints[pntz].values[0] == 0):\n",
    "            n = 0;\n",
    "        else:\n",
    "            xlocation = handPoints[pntx]\n",
    "            ylocation = handPoints[pnty]\n",
    "            zlocation = handPoints[pntz]\n",
    "            ax.scatter(xlocation, ylocation, zlocation, marker='v')\n",
    "    \n",
    "    crntClass = handPoints['Class'].values[0]\n",
    "    if (crntClass == 1):\n",
    "        title = 'Fist + Thumb out'\n",
    "    if(crntClass == 2):\n",
    "        title = 'Stop/Flat hand'\n",
    "    if (crntClass == 3):\n",
    "        title = 'Point with pointer finger'\n",
    "    if (crntClass == 4):\n",
    "        title = 'Point with pointer + middle finger'\n",
    "    if (crntClass == 5):\n",
    "        title = 'Grab'\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f98525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO create a rotateable 3D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68869c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a random hand gesture from the dataset to get a an idea of the data\n",
    "#TODO not working on linux, check why\n",
    "'''\n",
    "for _ in range(4):\n",
    "    rand_dp = np.random.randint(df_raw.shape[0], size=1)[0]\n",
    "    pltHand(df_raw[rand_dp:rand_dp+1] )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5729ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df: pd.DataFrame):\n",
    "\n",
    "    correlationMatrix = pd.DataFrame(df_raw).corr() \n",
    "    f = plt.figure(figsize=(12, 6))\n",
    "    plt.matshow(correlationMatrix, fignum=f.number)\n",
    "    plt.xticks(range(df_raw.shape[1]), df_raw.columns, fontsize=14, rotation=75)\n",
    "    plt.yticks(range(df_raw.shape[1]), df_raw.columns, fontsize=14)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e371b-a8fb-4546-a596-19e5c60a0d83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-processing\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db67d8ed",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows of user 4 and 7\n",
    "# Because they have significantly less data points\n",
    "df_raw = df_raw[df_raw['User'] != 4]\n",
    "df_raw = df_raw[df_raw['User'] != 7]\n",
    "df_raw.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba31201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop coordinates of point 10 and 11\n",
    "# More than 90% of the data is missing\n",
    "# Search for \"Hint 1\" for further information\n",
    "df_raw.drop(['X10', 'Y10', 'Z10', 'X11', 'Y11', 'Z11'], inplace=True, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d71ae2c",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ec922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compute PCA and plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e5717a-e460-4985-8ffd-e90171aac4d2",
   "metadata": {},
   "source": [
    "### Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d1899",
   "metadata": {},
   "source": [
    "### a. Extract features (min, max, mean, etc.) - df_aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e93f605-60b1-4ba3-9571-03afa0a4178a",
   "metadata": {},
   "source": [
    "Ideas for new features: (inspired from paper)<br>\n",
    "* number of markers\n",
    "* mean (per coordinate)\n",
    "* Eigenvalues and vectors of the points covariance matrix\n",
    "https://math.stackexchange.com/questions/2842830/why-does-the-eigen-decomposition-of-the-covariance-matrix-of-a-point-cloud-give\n",
    "* dimensions of the axis-aligned minimum bounding box centered on the mean\n",
    "\n",
    "Keep in mind that each feature has to aggregate the points in such a way that the result is order invariant!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data set we want to fill step by step\n",
    "df_aggregate= pd.DataFrame()\n",
    "# We dont want to change the original data set\n",
    "df_raw_dummy = df_raw.copy(deep=True)\n",
    "\n",
    "# Save the user and class column\n",
    "df_user = df_raw_dummy.pop('User')\n",
    "df_class = df_raw_dummy.pop('Class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6aa07a-8418-42ce-b560-099ecece123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the X, Y and Z columns\n",
    "df_x = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith('X')]]\n",
    "df_y = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith('Y')]]\n",
    "df_z = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith('Z')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the mean of the X, Y and Z columns\n",
    "for coordinate in ['X', 'Y', 'Z']:\n",
    "    df_aggregate[f'{coordinate}_mean'] = df_raw_dummy[df_raw_dummy.columns[pd.Series(df_raw_dummy.columns).str.startswith(coordinate)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b954b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the number of visible points (not occluded)\n",
    "df_aggregate['n_points'] = (df_raw_dummy.astype(bool).sum(axis=1))/3\n",
    "df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf820fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_dummy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bea0cdac",
   "metadata": {},
   "source": [
    "My idea:<br>\n",
    "find the orientation of a given cluster<br>\n",
    "(https://math.stackexchange.com/questions/2842830/why-does-the-eigen-decomposition-of-the-covariance-matrix-of-a-point-cloud-give)\n",
    "\n",
    "1. Rearange the dataset (1 point per row with X, Y, Z value)\n",
    "-> All points per row will be saved in a batch as new sub dataframe\n",
    "2. Compute the covariance matrix for each sub dataframe\n",
    "3. Calculate the Eigenvalues and Eigenvectors of the covariance matrix\n",
    "4. Concat created features to the dataframe\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25f1ea52",
   "metadata": {},
   "source": [
    "DISCLAIMER: <br>\n",
    "The following function can take up to 1 min!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c5a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume you have a DataFrame called 'df' with the columns ['X0', 'Y0', 'Z0', 'X1', 'Y1', 'Z1', 'X2', 'Y2', 'Z2']\n",
    "# Reorganize the dataframe to have each row as a batch of data\n",
    "# 'X0', 'Y0', 'Z0',\n",
    "# 'X1', 'Y1', 'Z1',\n",
    "# 'X2', 'Y2', 'Z2'\n",
    "\n",
    "# Create an empty list to store the batches of data\n",
    "batches = []\n",
    "\n",
    "# Iterate over the DataFrame and extract the batches of data\n",
    "for row in range(0, df_raw_dummy.shape[0]):\n",
    "\n",
    "    col_batch = []\n",
    "    # Extract a batch of data for the current row\n",
    "    for col in range(0, df_raw_dummy.shape[1], 3):\n",
    "        batch = df_raw_dummy.iloc[row, col:col+3]\n",
    "        # Rename the columns\n",
    "        batch.index = ['X', 'Y', 'Z']\n",
    "        #print(f'batch: {batch}')\n",
    "        col_batch.append(batch)\n",
    "    # Append the batch to the list\n",
    "    batches.append(col_batch)\n",
    "\n",
    "# Concatenate the batches of data under each other\n",
    "concat_batches = []\n",
    "for batch in batches:\n",
    "    concat_batch = pd.concat(batch, axis=1).transpose()\n",
    "    concat_batches.append(concat_batch)\n",
    "    # Remove rows with all zeros\n",
    "    concat_batch = concat_batch[(concat_batch.T != 0).any()]\n",
    "\n",
    "# Create a dictionary with the eigenvalues and eigenvectors as values\n",
    "eigen_dict = {'eigenvec_1_1': [],\n",
    "                'eigenvec_1_2': [],\n",
    "                'eigenvec_1_3': [],\n",
    "                'eigenvec_2_1': [],\n",
    "                'eigenvec_2_2': [],\n",
    "                'eigenvec_2_3': [],\n",
    "                'eigenvec_3_1': [],\n",
    "                'eigenvec_3_2': [],\n",
    "                'eigenvec_3_3': [],\n",
    "              'eigenval_1': [],\n",
    "              'eigenval_2': [],\n",
    "              'eigenval_3': []}\n",
    "\n",
    "# Create the DataFrame\n",
    "eigen_df = pd.DataFrame(eigen_dict)\n",
    "\n",
    "# Compute the covariance matrix for each batch\n",
    "for concat_batch in concat_batches:\n",
    "    # Compute the covariance matrix\n",
    "    cov_matrix = np.cov(concat_batch, rowvar=False)\n",
    "    # Compute the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "    # Add the eigenvalues and eigenvectors to the DataFrame\n",
    "    # Store eigenvector 1\n",
    "    eigen_dict['eigenvec_1_1'].append(eigenvectors[0, 0])\n",
    "    eigen_dict['eigenvec_1_2'].append(eigenvectors[1, 0])\n",
    "    eigen_dict['eigenvec_1_3'].append(eigenvectors[2, 0])\n",
    "    # Store eigenvector 2\n",
    "    eigen_dict['eigenvec_2_1'].append(eigenvectors[0, 1])\n",
    "    eigen_dict['eigenvec_2_2'].append(eigenvectors[1, 1])\n",
    "    eigen_dict['eigenvec_2_3'].append(eigenvectors[2, 1])\n",
    "    # Store eigenvector 3\n",
    "    eigen_dict['eigenvec_3_1'].append(eigenvectors[0, 2])\n",
    "    eigen_dict['eigenvec_3_2'].append(eigenvectors[1, 2])\n",
    "    eigen_dict['eigenvec_3_3'].append(eigenvectors[2, 2])\n",
    "    # Store eigenvalues\n",
    "    eigen_dict['eigenval_1'].append(eigenvalues[0])\n",
    "    eigen_dict['eigenval_2'].append(eigenvalues[1])\n",
    "    eigen_dict['eigenval_3'].append(eigenvalues[2])\n",
    "\n",
    "# Finally add generated features to the DataFrame\n",
    "df_aggregate = pd.concat([df_aggregate, pd.DataFrame(eigen_dict)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485aefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user and class information to the new data set after the feature extraction\n",
    "df_aggregate['User'] = df_user\n",
    "df_aggregate['Class'] = df_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ef523fc",
   "metadata": {},
   "source": [
    "**Evaluation Strategy**:<br>\n",
    "We will use a k-Fold cross-validation to evaluate our model <br>\n",
    "We randomly choose 2 User for the test set <br>\n",
    "Then we remove the users from the selectable list so that each user is in the test data set at most once over all k runs <br>\n",
    "For the next split we again choose 2 random User, and so on<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_train_test_user(df:pd.DataFrame, user_list:list, num_user_test:int=2):\n",
    "    '''This function returns the indices for the training and test set.\n",
    "    The function randomly selects two users for the test set and the remaining\n",
    "    users for the training set.\n",
    "    \n",
    "    return: train_indices, test_indices'''\n",
    "\n",
    "    # Create a list of indices for the training and test set\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Generate 2 random numbers between 0 and 14\n",
    "    test_user_1, test_user_2 = random.sample(user_list, num_user_test)\n",
    "    print(f'User picked for test set: {test_user_1}, {test_user_2}')\n",
    "    \n",
    "\n",
    "    # Iterate over the users\n",
    "    for user in user_list:\n",
    "        # Get the indices for the current user\n",
    "        indices = df[df['User'] == user].index\n",
    "        # Append the indices to the list\n",
    "        if user == test_user_1 or user == test_user_2:\n",
    "            test_indices.extend(indices)\n",
    "        else:\n",
    "            train_indices.extend(indices)\n",
    "    \n",
    "    # Remove the test users from the user list so they cannot be selected again\n",
    "    user_list = [x for x in user_list if x != test_user_1 and x != test_user_2]\n",
    "\n",
    "    return train_indices, test_indices, user_list\n",
    "\n",
    "def custom_cv_approach(df:pd.DataFrame, user_list:list, num_user_test:int=2):\n",
    "    '''\n",
    "    each user is iteratively left out from training and used as a test set. \n",
    "    We then tests the generalization of the algorithm to new users. \n",
    "    A 'User' attribute is provided to accomodate this strategy. \n",
    "    '''\n",
    "    def cv_ratio(y_test, df):\n",
    "        print(f'Ratio of test set: {len(y_test)/len(df)}')\n",
    "    \n",
    "    # Get the indices for the training and test set\n",
    "    train_indices, test_indices, user_list = get_train_test_user(df, user_list, num_user_test)\n",
    "    # Create the training and test set\n",
    "    X_train = df.iloc[train_indices, :]\n",
    "    y_train = X_train.pop('Class')\n",
    "    X_train.pop('User')\n",
    "    X_test = df.iloc[test_indices, :]\n",
    "    y_test = X_test.pop('Class')\n",
    "    X_test.pop('User')\n",
    "\n",
    "    # Print the ratio of the test set\n",
    "    cv_ratio(y_test, df)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, user_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_group = df_aggregate.groupby(['User'], sort=False)\n",
    "user_group.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d51c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add augmentation to the data set.\n",
    "# e.g. add Jitter or Shuffle data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5dd5b4a",
   "metadata": {},
   "source": [
    "### c.I Split data - Wrong way"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9dd3b3ea",
   "metadata": {},
   "source": [
    "#### Demonstration data set (WRONG WAY) - mixed user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9487229",
   "metadata": {},
   "source": [
    "******************************************************\n",
    "DEMONSTRATION: this shows how NOT to do it:<br>\n",
    "Splitting the naive way (similar data points will be in both sets)\n",
    "******************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7940eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c585d02-1dc7-41bc-a8fe-e47d0d70e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into train and test set\n",
    "X_train_mixed, X_test_mixed, y_train_mixed, y_test_mixed = train_test_split(df_raw, df_raw['Class'], test_size=0.25)\n",
    "user_group = df_raw.groupby(['User'], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb68af6",
   "metadata": {},
   "source": [
    "We normalize the data using a Min-Max-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data with MinMaxScaler\n",
    "\n",
    "# Create the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the training data\n",
    "scaler.fit(X_train_mixed)\n",
    "\n",
    "# Transform the training and test data\n",
    "X_train_mixed = scaler.transform(X_train_mixed)\n",
    "X_test_mixed = scaler.transform(X_test_mixed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63d550bc",
   "metadata": {},
   "source": [
    "#### c.II Split data properly (but still on raw data set)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a941cf30",
   "metadata": {},
   "source": [
    "We now have a CV loop:\n",
    "I split the data in the same loop, where I train the model for a specific k-fold <br>\n",
    "Therefore I dont split the data beforehand in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab41a1-9b02-4916-9089-38a43d021429",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Testing Phase I: Baseline Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "027c4ee0",
   "metadata": {},
   "source": [
    "After we have trained all the models, we want to compare the model performance using selected metrics. Therefore we need to save the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b972908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['model', 'Accuracy', 'Precision', 'Recall', 'F1_score'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fca0de32",
   "metadata": {},
   "source": [
    "First, we write a training function to have a common interface for all conventional machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df:pd.DataFrame, model_func: Callable, scaler:str, kwargs_dict:dict):\n",
    "    '''This function provides a common interface to train the classic ml models.\n",
    "    In a loop we iterate over different train and test sets and train the model.\n",
    "    We leave out k users from the data set and use them as test set.\n",
    "    '''\n",
    "\n",
    "    # Create a list of users\n",
    "    user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "    # Number of users to be used for the test set\n",
    "    num_user_test = 2\n",
    "    num_of_iterations = 4\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    X_test_best = None\n",
    "    y_test_best = None\n",
    "\n",
    "    # Save evaluation metrics in a dictionary\n",
    "    eval_dict = {'train': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []},\n",
    "                    'test': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []}}\n",
    "\n",
    "    for i in range(num_of_iterations):\n",
    "\n",
    "        print('*'*50)\n",
    "        print(f'CV Run: {i}')\n",
    "\n",
    "        model = model_func(**kwargs_dict)\n",
    "\n",
    "        # Split the data\n",
    "        X_train, y_train, X_test, y_test, user_list = custom_cv_approach(df, user_list, num_user_test=num_user_test)\n",
    "\n",
    "        if scaler == 'normalize':\n",
    "            # Normalize the data\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        elif scaler == 'standard':\n",
    "            # Standard Scale the data\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "        else:\n",
    "            print('No scaling applied')\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "        model_acc = model.score(X_test, y_test)\n",
    "        \n",
    "        # Print the results\n",
    "        print('Train accuracy: ', model.score(X_train, y_train))\n",
    "        print('(CV-) Test accuracy: ', model_acc)\n",
    "\n",
    "        # Save the results\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        train_acc = accuracy_score(y_train, y_pred_train)\n",
    "        train_precision = precision_score(y_train, y_pred_train)\n",
    "        train_recall = recall_score(y_train, y_pred_train)\n",
    "        f1_score_train = f1_score(y_train, y_pred_train)\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'train', train_acc, train_precision, train_recall, f1_score_train)\n",
    "\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        val_acc = accuracy_score(y_test, y_pred_test)\n",
    "        val_precision = precision_score(y_test, y_pred_test)\n",
    "        val_recall = recall_score(y_test, y_pred_test)\n",
    "        f1_score_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'test', val_acc, val_precision, val_recall, f1_score_test)\n",
    "\n",
    "        # Save best model\n",
    "        if model_acc > best_acc:\n",
    "            best_model = model\n",
    "            best_acc = model_acc\n",
    "            X_test_best = X_test\n",
    "            y_test_best = y_test\n",
    "\n",
    "        return best_model, X_test_best, y_test_best, eval_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88505742",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b14d2-50f2-439f-88cf-9ace62e40671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#You need to check model descriptions for the hyperparameters. \n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier\n",
    "#-----------------------------------------------------------------\n",
    "# Number of trees in the forest:\n",
    "n_estimators = 10\n",
    "# Number of features to consider when looking for the best split:\n",
    "max_features = 'auto'\n",
    "# Maximum depth of the tree:\n",
    "max_depth = None\n",
    "# Minimum number of samples required to split an internal node:\n",
    "min_samples_split = 2\n",
    "# Minimum number of samples required to be at a leaf node:\n",
    "min_samples_leaf = 1\n",
    "# Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. \n",
    "max_leaf_nodes = None\n",
    "# Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree:\n",
    "bootstrap = False\n",
    "# Whether to use out-of-bag samples to estimate the generalization score. Only available if bootstrap=True.\n",
    "oob_score = False\n",
    "# Number of jobs to run in parallel. (-1) means use all.\n",
    "n_jobs = -1\n",
    "# Random state\n",
    "random_state = 2023\n",
    "#-----------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance_rf(rfc_model:RandomForestClassifier, feature_names:list):\n",
    "    '''\n",
    "    This function plots the feature importance of the random forest classifier.\n",
    "\n",
    "    Parameters:\n",
    "        rfc_model: Random Forest Classifier model\n",
    "        X_train: Training data set, only for the feature names\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_importance = np.array(rfc_model.feature_importances_)\n",
    "    feature_names = np.array(feature_names)\n",
    "\n",
    "    data={'Feature names':feature_names,'Feature importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    fi_df.sort_values(by=['Feature importance'], ascending=False,inplace=True)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x=fi_df['Feature importance'], y=fi_df['Feature names'])\n",
    "    plt.title('Random Forest Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89ca841b",
   "metadata": {},
   "source": [
    "### a) Mixed dataset (wrong way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35feea9-0ba5-44a0-8654-ccb4bf33744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the classifier:\n",
    "RFC_demo = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \\\n",
    "                              max_leaf_nodes=max_leaf_nodes, bootstrap=bootstrap,oob_score=oob_score, n_jobs=n_jobs, random_state=random_state)\n",
    "RFC_demo.fit(X_train_mixed, y_train_mixed)\n",
    "RFC_demo.score(X_test_mixed, y_test_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_data_report = Report('rfc_mixed', RFC_demo, X_test_mixed, y_test_mixed, description=['mixed_data', 'raw features'])\n",
    "print(mixed_data_report)\n",
    "precision_recall_multiclass(RFC_demo, X_test_mixed, y_test_mixed)\n",
    "y_pred_mixed = RFC_demo.predict(X_test_mixed)\n",
    "plot_cm(y_test_mixed, y_pred_mixed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e18ce2e8",
   "metadata": {},
   "source": [
    "Too good to be true...<br>\n",
    "This was a demonstration how we should not split the data set!\n",
    "Many people on kaggel etc. made this mistake\n",
    "\n",
    "From now on we will not use this (wrong) processed data set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54fc628b",
   "metadata": {},
   "source": [
    "### b) Custom CV - with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc78cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#Random Forest raw features\n",
    "rf_raw_hyperparams = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'max_leaf_nodes': max_leaf_nodes,\n",
    "                'bootstrap': bootstrap,\n",
    "                'oob_score': oob_score,\n",
    "                'n_jobs': n_jobs,\n",
    "                'random_state': random_state}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_raw, RandomForestClassifier, 'normalize', rf_raw_hyperparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edec0e68",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d553aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_w_cv_data_report = Report('rfc_raw', best_model, X_test_best, y_test_best, description=['cv_data', 'raw features'])\n",
    "df_results = raw_w_cv_data_report.get_report_as_df(df_results)\n",
    "print(raw_w_cv_data_report)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred_split_raw = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred_split_raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dbac506",
   "metadata": {},
   "source": [
    "Here we can see that its difficult for the model to classify the \"Fist\" and \"Point2\" data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca51555",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff838528",
   "metadata": {},
   "source": [
    "### c) Custom CV - with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From now on we will use the following data\n",
    "df_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd5890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#Random Forest raw features\n",
    "rf_extract_hyperparams = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'max_leaf_nodes': max_leaf_nodes,\n",
    "                'bootstrap': bootstrap,\n",
    "                'oob_score': oob_score,\n",
    "                'n_jobs': n_jobs,\n",
    "                'random_state': random_state}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_aggregate, RandomForestClassifier, 'normalize', rf_extract_hyperparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe45dba1",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_w_cv_data_report = Report('rfc_extract', best_model, X_test_best, y_test_best, description=['cv_data', 'extracted features'])\n",
    "df_results = extract_w_cv_data_report.get_report_as_df(df_results)\n",
    "print(extract_w_cv_data_report)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred_cv_extract = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred_cv_extract)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "979b330a",
   "metadata": {},
   "source": [
    "With the extracted features the model improved in predicting \"Point2\" data points, but the perfomance for predicting \"Grab\" decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a49155",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = df_aggregate.columns.to_list()\n",
    "feature_list.remove('User')\n",
    "feature_list.remove('Class')\n",
    "plot_feature_importance_rf(best_model, feature_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cf1a3af",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "penalty = 'l2'\n",
    "C = 1.0 #regularization strength. The smaller the value, the stronger the regularization.\n",
    "random_state = 2023\n",
    "solver = 'lbfgs' # One of the possible solver for multiclass problems (‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’)\n",
    "max_iter = 300"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "965311c8",
   "metadata": {},
   "source": [
    "### a) Custom CV - with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92fde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#Logistic regression raw features\n",
    "lg_raw_hyperparams = {'penalty': penalty,\n",
    "                'C': C,\n",
    "                'random_state': random_state,\n",
    "                'solver': solver,\n",
    "                'max_iter': max_iter}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_raw, LogisticRegression, 'standard', lg_raw_hyperparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d681f10a",
   "metadata": {},
   "source": [
    "Error occured:\n",
    "ConvergenceWarning: lbfgs failed to converge (status=1)\n",
    "-> increase max_iter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b56ac0e8",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_w_cv_data_report_lg = Report('lg_raw', best_model, X_test_best, y_test_best, description=['LogReg', 'cv_data', 'raw features'])\n",
    "df_results = raw_w_cv_data_report_lg.get_report_as_df(df_results)\n",
    "print(raw_w_cv_data_report_lg)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10e5efb2",
   "metadata": {},
   "source": [
    "### b) Custom CV - with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#Logistic regression extract features\n",
    "lg_extract_hyperparams = {'penalty': penalty,\n",
    "                'C': C,\n",
    "                'random_state': random_state,\n",
    "                'solver': solver,\n",
    "                'max_iter': max_iter}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_aggregate, LogisticRegression, 'standard', lg_extract_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812cd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With custom cross validation\n",
    "\n",
    "# Create a list of users\n",
    "user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "# Number of users to be used for the test set\n",
    "num_user_test = 2\n",
    "num_of_iterations = 4\n",
    "\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "X_test_best = None\n",
    "y_test_best = None\n",
    "\n",
    "for i in range(num_of_iterations):\n",
    "\n",
    "    print('*'*50)\n",
    "    print(f'CV Run: {i}')\n",
    "\n",
    "    logReg_split_raw = LogisticRegression(penalty=penalty, C=C,random_state=random_state, solver=solver)\n",
    "\n",
    "    # Split the data\n",
    "    X_train_cv_extract, y_train_cv_extract, X_test_cv_extract, y_test_cv_extract, user_list = custom_cv_approach(df_aggregate, user_list, num_user_test=num_user_test)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train_cv_extract)\n",
    "    X_train_cv_extract = scaler.transform(X_train_cv_extract)\n",
    "    X_test_cv_extract = scaler.transform(X_test_cv_extract)\n",
    "\n",
    "    # Fit the model\n",
    "    logReg_split_raw.fit(X_train_cv_extract, y_train_cv_extract)\n",
    "    model_acc = logReg_split_raw.score(X_test_cv_extract, y_test_cv_extract)\n",
    "    \n",
    "    # Print the results\n",
    "    print('Train accuracy: ', logReg_split_raw.score(X_train_cv_extract, y_train_cv_extract))\n",
    "    print('(CV-) Test accuracy: ', model_acc)\n",
    "\n",
    "    # Save best model\n",
    "    if model_acc > best_acc:\n",
    "        best_model = logReg_split_raw\n",
    "        best_acc = model_acc\n",
    "        X_test_best = X_test_cv_extract\n",
    "        y_test_best = y_test_cv_extract\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "708a2be5",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_w_cv_data_report_lg = Report('lg_extract', best_model, X_test_best, y_test_best, description=['LogReg', 'cv_data', 'extracted features'])\n",
    "df_results = extract_w_cv_data_report_lg.get_report_as_df(df_results)\n",
    "print(extract_w_cv_data_report_lg)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd3e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08235963",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19328cee",
   "metadata": {},
   "source": [
    "### a) Custom CV - with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96991f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#SVC_raw\n",
    "svc_raw_hyperparams = {\n",
    "    'C': 1.0, #regularization strength. The smaller the value, the stronger the regularization.\n",
    "    'gamma':'scale',\n",
    "    'kernel': 'rbf',\n",
    "    'decision_function_shape': 'ovo',\n",
    "    'random_state': 2023,\n",
    "    'max_iter': -1, # -1 means no limit\n",
    "    'cache_size': 200, # in MB\n",
    "    'probability': True # needed for predict_proba later on\n",
    "}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_raw, SVC, 'standard', svc_raw_hyperparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c3a90c1",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06212600",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_w_cv_data_report_svm = Report('svm_raw', best_model, X_test_best, y_test_best, description=['SVM', 'cv_data', 'raw features'])\n",
    "df_results = raw_w_cv_data_report_svm.get_report_as_df(df_results)\n",
    "print(raw_w_cv_data_report_svm)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f68ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baa6f14d",
   "metadata": {},
   "source": [
    "### b) Custom CV - with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "#SVC_aggregate\n",
    "svc_extract_hyperparams = {\n",
    "    'C': 1.0, #regularization strength. The smaller the value, the stronger the regularization.\n",
    "    'gamma':'scale',\n",
    "    'kernel': 'rbf',\n",
    "    'decision_function_shape': 'ovo',\n",
    "    'random_state': 2023,\n",
    "    'max_iter': -1, # -1 means no limit\n",
    "    'cache_size': 200, # in MB\n",
    "    'probability': True # needed for predict_proba later on\n",
    "}\n",
    "\n",
    "best_model, X_test_best, y_test_best, eval_dict = train_model(df_aggregate, SVC, 'standard', svc_extract_hyperparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd09d117",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2577b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_w_cv_data_report_svm = Report('svm_extract', best_model, X_test_best, y_test_best, description=['SVM', 'cv_data', 'extracted features'])\n",
    "df_results = extract_w_cv_data_report_svm.get_report_as_df(df_results)\n",
    "print(extract_w_cv_data_report_svm)\n",
    "precision_recall_multiclass(best_model, X_test_best, y_test_best)\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b593805",
   "metadata": {},
   "source": [
    "TODO other models to try <br>\n",
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da30056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO boxplot of the results\n",
    "'''\n",
    "ax = sns.boxplot(data = f2_df, linewidth=1, showfliers=False)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "sns.set(rc = {'figure.figsize':(8,10)})\n",
    "ax.set(ylabel='F2-Score')\n",
    "ax.set_title('F2-Score Deviation of different Models')\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57427d49",
   "metadata": {},
   "source": [
    "## Conclusion Testing Phase I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66077b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison(df_results):\n",
    "    '''\n",
    "    Plot a comparison of the models based on the evaluation metrics\n",
    "    '''\n",
    "\n",
    "    df = df_results.copy()\n",
    "    # Set the model as the index\n",
    "    df.set_index('model', inplace=True)\n",
    "    # Create a 2x2 grid of subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "    # Create color list\n",
    "    colors = ['tab:blue', 'tab:red', 'tab:green', 'tab:orange', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "\n",
    "\n",
    "    # Plot each metric in a subplot\n",
    "    for i, metric in enumerate(df.columns):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        axs[row, col].bar(df.index, df[metric], color=colors[:len(df.index)], width=0.3)\n",
    "        axs[row, col].set_xlabel('Model')\n",
    "        axs[row, col].set_ylabel(metric)\n",
    "        axs[row, col].set_title(f'{metric} Comparison')\n",
    "        axs[row, col].set_ylim([0, 1])\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    plt.tight_layout()\n",
    "    # Display the plots\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_comparison(df_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4539e6b0",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Extracted features?\n",
    "* good, we see an improvement ...\n",
    "\n",
    "Confusion Matrix:\n",
    "* what cases are difficult\n",
    "* which are easy\n",
    "* explanation why\n",
    "\n",
    "Feature reduction\n",
    "* good/bad\n",
    "* PCA\n",
    "* which models got worses\n",
    "\n",
    "Best model:\n",
    "* e.g. rf with extracted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7e387-b801-43da-ba43-81f3c958aad4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 4. Testing Phase II: Model Develepoment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5326581a",
   "metadata": {},
   "source": [
    "## Base MLP structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c7bd1af",
   "metadata": {},
   "source": [
    "* Activation Functions\n",
    "    - output layer: one neuron for each class (5)\n",
    "    - we want the the probability of the each class, -> **softmax**\n",
    "    - hidden Layer: start with **ReLU**\n",
    "\n",
    "* Optimizer\n",
    "    - **rmsprop**\n",
    "\n",
    "* loss\n",
    "    - **categorical_crossentropy**\n",
    "\n",
    "* Hidden Layers and Number of Neurons\n",
    "    - start with small architecture, increase size\n",
    "\n",
    "* Metric\n",
    "    - **accuracy**\n",
    "    - **precission**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def build_mlp_model(name:str, hyperparams:dict, input_shape: tuple, output_shape: int) -> keras.Sequential:\n",
    "    'Build MLP classification network'\n",
    "\n",
    "    model = keras.Sequential(name=name)\n",
    "    model.add(keras.Input(shape=input_shape))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(output_shape, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=hyperparams['optimizer'], loss=hyperparams['loss'], metrics=hyperparams['metrics'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(hist, parameters, name:str):\n",
    "    \n",
    "    plt.plot(hist['epoch'][:],hist['loss'][:], \"k--\", linewidth=1.5, label=\"Training\")\n",
    "    plt.plot(hist['epoch'][:],hist['val_loss'][:], \"b-.\", linewidth=1.5, label=\"CV test\")\n",
    "    plt.legend()\n",
    "    plt.ylim(0,max(hist['loss'][:].max(), hist['val_loss'][:].max())+0.2)\n",
    "    plt.xlabel(\"Epochs\"),  plt.ylabel(\"categorical_crossentropy\")\n",
    "\n",
    "    plt.title(f'Learning Curve: {name}', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_learning_curves(name, hyperparams):\n",
    "    \"\"\"\n",
    "    Plot the learning curves for each cv run\n",
    "    \"\"\"\n",
    "\n",
    "    # Load hist of every cv run\n",
    "\n",
    "    all_hist = []\n",
    "\n",
    "    for i in range(4):\n",
    "        hist = load_history(f'{name}_cv{i}')\n",
    "        all_hist.append(hist)\n",
    "        \n",
    "    # Plot the learning curves for each cv run\n",
    "    for i in range(4):\n",
    "        plot_learning_curves(all_hist[i], hyperparams, f'{name}_cv{i}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97854963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(hist, name):\n",
    "\n",
    "    # Get path to save the history\n",
    "    hist_folder = 'model/single_run/history'\n",
    "    model_path = join(hist_folder, name)\n",
    "    \n",
    "    with open(model_path, 'wb') as file_pi:\n",
    "        pickle.dump(hist, file_pi)\n",
    "\n",
    "def load_history(name):\n",
    "\n",
    "    # Get path to save the history\n",
    "    hist_folder = 'model/single_run/history'\n",
    "    model_path = join(hist_folder, name)\n",
    "    \n",
    "    with open(model_path, 'rb') as file_pi:\n",
    "        history = pickle.load(file_pi)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e74265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name):\n",
    "\n",
    "    # Get path to save the history\n",
    "    model_folder = 'model/single_run'\n",
    "    model_path = join(model_folder, name)\n",
    "    \n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a376ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_used_parameters(parameters:dict):\n",
    "    print('Used parameters:')\n",
    "    for parameter, value in parameters.items():\n",
    "        print(f'{parameter}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_one_hot(one_hot_encoded):\n",
    "    return np.argmax(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1_score_mlp(model, X, y):\n",
    "    # Calculate f1 score of mlp\n",
    "    y_pred1 = model.predict(X)\n",
    "    y_pred = np.argmax(y_pred1, axis=1)\n",
    "\n",
    "    # to one hot encoding\n",
    "    y_pred = to_categorical(y_pred)\n",
    "\n",
    "    return f1_score(y, y_pred , average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda9460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_mlp_model(name, df:pd.DataFrame, hyperparams:dict):\n",
    "    '''\n",
    "    Train a MLP model with k-fold cross validation (leave n users out strategy)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str, Name of the model.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    best_model : keras.Sequential, The best model.\n",
    "    best_acc : float, The best accuracy.\n",
    "    X_test_best : numpy.ndarray, The best test set.\n",
    "    y_test_best : numpy.ndarray, The best test set.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    # Create a list of users\n",
    "    user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "    # Number of users to be used for the test set\n",
    "    num_user_test = 2\n",
    "    num_of_iterations = 4\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    X_test_best = None\n",
    "    y_test_best = None\n",
    "\n",
    "    all_acc_val = []\n",
    "    all_prec_val = []\n",
    "\n",
    "    # Evaluation dict\n",
    "    eval_dict = {'train': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []},\n",
    "                 'test': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []}}\n",
    "\n",
    "    describe_model = True\n",
    "\n",
    "    for i in range(num_of_iterations):\n",
    "\n",
    "        print('*'*50)\n",
    "        print(f'CV Run: {i}')\n",
    "\n",
    "        # Split the data #TODO rename to X_train etc. because function also use by raw and later pca\n",
    "        X_train_cv_extract, y_train_cv_extract, X_test_cv_extract, y_test_cv_extract, user_list = custom_cv_approach(df, user_list, num_user_test=num_user_test)\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train_cv_extract)\n",
    "        X_train_cv_extract = scaler.transform(X_train_cv_extract)\n",
    "        X_test_cv_extract = scaler.transform(X_test_cv_extract)\n",
    "        # Befor one hot encoding, class has to start at 0\n",
    "        y_train_cv_extract = y_train_cv_extract-1\n",
    "        y_test_cv_extract = y_test_cv_extract-1\n",
    "        # y label to one hot encode\n",
    "        y_train_cv_extract = to_categorical(y_train_cv_extract)\n",
    "        y_test_cv_extract = to_categorical(y_test_cv_extract)\n",
    "\n",
    "        # Build the model\n",
    "        # TODO\n",
    "        mlp_model = build_mlp_model(name, hyperparams, input_shape=X_train_cv_extract.shape[1:], output_shape=y_train_cv_extract.shape[1])\n",
    "\n",
    "        # Only print the model summary once\n",
    "        if describe_model:\n",
    "            mlp_model.summary()\n",
    "            describe_model = False\n",
    "\n",
    "        # Create callback\n",
    "        # Use early stopping later because it is a form of regularization\n",
    "        #early_stop_callback = keras.callbacks.EarlyStopping(monitor=\"val_categorical_accuracy\", min_delta=1e-4, patience=5, verbose=1)\n",
    "        checkpoint_callback = keras.callbacks.ModelCheckpoint(f'model/single_run/{name}_cv{i}.h5', save_best_only=True)\n",
    "\n",
    "        # Train the model\n",
    "        history = mlp_model.fit(X_train_cv_extract, \n",
    "                                y_train_cv_extract, \n",
    "                                epochs=hyperparams['num_epochs'], \n",
    "                                batch_size= hyperparams['batch_size'],\n",
    "                                validation_data=(X_test_cv_extract, y_test_cv_extract),\n",
    "                                verbose=1,\n",
    "                                shuffle=True,\n",
    "                                callbacks=[checkpoint_callback])\n",
    "\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "\n",
    "        # Save the history\n",
    "        save_history(hist, f'{name}_cv{i}')\n",
    "\n",
    "        #Evaluating the training performance:\n",
    "        train_loss, train_acc, train_precision, train_recall = mlp_model.evaluate(x=X_train_cv_extract, y=y_train_cv_extract, batch_size=hyperparams['batch_size'], verbose=3)\n",
    "        f1_score_train = calc_f1_score_mlp(mlp_model, X_train_cv_extract, y_train_cv_extract)\n",
    "\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'train', train_acc, train_precision, train_recall, f1_score_train)\n",
    "        print('-'*70)\n",
    "        print('Evaluation of training Data: \\n', 'training loss: ', train_loss, 'training accuracy: ', train_acc)\n",
    "\n",
    "        #Evaluating the CV pperformance:\n",
    "        val_loss, val_acc, val_precision, val_recall = mlp_model.evaluate(x=X_test_cv_extract, y=y_test_cv_extract, batch_size=hyperparams['batch_size'], verbose=0)\n",
    "        f1_score_test = calc_f1_score_mlp(mlp_model, X_test_cv_extract, y_test_cv_extract)\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'test', val_acc, val_precision, val_recall, f1_score_test)\n",
    "        all_acc_val.append(val_acc)\n",
    "        all_prec_val.append(val_precision)\n",
    "        print('Evaluation of validation Data: \\n', 'cv loss: ', val_loss, 'cv accuracy: ', val_acc)\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_model = mlp_model\n",
    "            best_acc = val_acc\n",
    "            X_test_best = X_test_cv_extract\n",
    "            y_test_best = y_test_cv_extract\n",
    "\n",
    "    #Lets see the overall score as average of the scores of all the folds:\n",
    "    print('-'*70)\n",
    "    print('(all CV runs combined)')\n",
    "    print('Mean Accuracy  for the validation dataset: ', np.mean(all_acc_val))\n",
    "    print('Mean Precision for the validation dataset: ', np.mean(all_prec_val))\n",
    "    print('-'*70)\n",
    "\n",
    "    # Save the model\n",
    "    best_model.save(f'model/single_run/{name}_best_model.h5')\n",
    "\n",
    "    # Save the evaluation dict\n",
    "    save_eval_dict_pkl(eval_dict, f'{name}_eval_dict')\n",
    "\n",
    "    # Plot the learning curves\n",
    "    plot_learning_curves(hist, hyperparams, name)\n",
    "\n",
    "    return best_model, best_acc, X_test_best, y_test_best, eval_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "#TODO set number of epochs to 15\n",
    "#TODO 45 per k fold (4 folds) will take 5 hours #40 is fine # 35 is fine\n",
    "#TODO use hidden layer and units hl\n",
    "hyperparams = {'num_epochs': 35,\n",
    "               'batch_size':10,\n",
    "               'hidden_layer':2,\n",
    "               'units_hidden_layer': 32,\n",
    "               'activation_hidden': 'relu',\n",
    "               'activation_output': 'softmax',\n",
    "               'loss': 'categorical_crossentropy',\n",
    "               'metrics': ['categorical_accuracy', 'Precision', tf.keras.metrics.Recall()],\n",
    "               'optimizer': keras.optimizers.legacy.Adam(),\n",
    "               'initialization': '-',\n",
    "               'weight regularisation l2': '-',\n",
    "               'dropout': '-',  # typically between 0.3 and 0.5 (half of weights get 0)\n",
    "               'early Stopping': 'False'} "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1d357fe",
   "metadata": {},
   "source": [
    "### a) Custom CV - with raw data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6aad82d",
   "metadata": {},
   "source": [
    "To get an Idea How long the model trains: <br>\n",
    "13 min 30 sec for 4 runs\n",
    "* each trains for 2 epochs\n",
    "\n",
    "Highly depends on the used Hardware! <br>\n",
    "Here we use an M1 macbook with GPU tf vesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'mlp_base_model_raw'\n",
    "df = df_raw\n",
    "best_model, best_acc, X_test_best, y_test_best, eval_dict = train_k_mlp_model(name, df, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_learning_curves(name, {'test': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc184952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust to mlp, KeyError: 'accuracy'\n",
    "data_report_mlp_base_raw = Report('mlp_raw', best_model, X_test_best, y_test_best, description=['MLP base', 'cv_data', 'raw features'])\n",
    "#df_results = data_report_mlp_base_raw.get_report_as_df(df_results)\n",
    "print(data_report_mlp_base_raw)\n",
    "\n",
    "# Prepare data to be compatible with confusion matrix function\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "y_pred = np.argmax(y_pred, axis=1)+1\n",
    "y_test_best = np.argmax(y_test_best, axis=1)+1\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741bae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad78e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mode = 'retrain' # 'retrain' or 'load_model'\n",
    "if run_mode == 'load_model':\n",
    "    hist = load_history('mlp_base_model_raw_cv3')\n",
    "    plot_learning_curves(hist, hyperparams, 'test')\n",
    "    eval_dict = load_eval_dict_pkl('mlp_base_model_raw_eval_dict')\n",
    "    plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d1e337a",
   "metadata": {},
   "source": [
    "First I tried a model with 32 16 8 units in the hidden layer<br>\n",
    "the validation los increased rigth from the beginning while the test loss was decreasing, which is a sign of overfitting<br>\n",
    "insert pic "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d00860b9",
   "metadata": {},
   "source": [
    "### b) Custom CV - with extracted features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98938d2b",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'mlp_base_model_extracted'\n",
    "df = df_aggregate\n",
    "best_model, best_acc, X_test_best, y_test_best, eval_dict = train_k_mlp_model(name, df, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d563fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_learning_curves(name, {'test': 'test'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "631c4933",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO save hist in list or load hist of every model and plot learning curve of every cv model\n",
    "# retrain model on whole data (validation + train) leave one user out as test set (instead of best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_report_mlp_base_raw = Report('mlp_extract', best_model, X_test_best, y_test_best, description=['MLP base', 'cv_data', 'extracted features'])\n",
    "#df_results = data_report_mlp_base_raw.get_report_as_df(df_results)\n",
    "print(data_report_mlp_base_raw)\n",
    "\n",
    "# Prepare data to be compatible with confusion matrix function\n",
    "y_pred = best_model.predict(X_test_best)\n",
    "y_pred = np.argmax(y_pred, axis=1)+1\n",
    "y_test_best = np.argmax(y_test_best, axis=1)+1\n",
    "plot_cm(y_test_best, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe123af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_dict_barplot_new(eval_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8aa0d448",
   "metadata": {},
   "source": [
    "## PointNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "289f5969",
   "metadata": {},
   "source": [
    "Note: for this archtitecture we have to use the original, raw data because we need a Point Cloud!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37dad2d5",
   "metadata": {},
   "source": [
    "From the Paper: \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" (Charles R. Qi et al)\n",
    "https://arxiv.org/abs/1612.00593"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6de8251",
   "metadata": {},
   "source": [
    "DISCLAIMER:\n",
    "Implementation with Keras:<br>\n",
    "https://keras.io/examples/vision/pointnet/\n",
    "\n",
    "Here we replicate the network architecture published in the original paper with the help of this blogpost!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a180ad6b",
   "metadata": {},
   "source": [
    "General\n",
    "* Point cloud =  a geometric data structure with irregular format\n",
    "* paper proposes a novel neural network called PointNet\n",
    "* PointNet: directly consumes point clouds + respects the permutation invariance of points in the input\n",
    "* unified architecture for object classification, part segmentation, and scene semantic parsing\n",
    "* simple, efficient, and effective\n",
    "\n",
    "Architecture\n",
    "* deal with unordered input set: use of a single symmetric function, max pooling\n",
    "* network learns a set of optimization functions/criteria that select interesting or informative points of the point cloud and encode the reason for their selection\n",
    "* final fully connected layers: aggregate these learnt optimal values into the global descriptor for the entire shape (shape classification) or are used to predict per point labels (shape segmentation)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59df0649",
   "metadata": {},
   "source": [
    "Each convolution and fully-connected layer (with exception for end layers) consits of \n",
    "* Convolution / Dense\n",
    "* Batch Normalization\n",
    "* ReLU Activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a58e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d5fc07b",
   "metadata": {},
   "source": [
    "PointNet consists of two core components\n",
    "* primary MLP network\n",
    "* transformer net (T-net)\n",
    "    * aims to learn an affine transformation matrix by its own mini network\n",
    "    * used twice:\n",
    "        * 1.to transform the input features (n, 3) into a canonical representation\n",
    "        * 2.affine transformation for alignment in feature space (n, 3)\n",
    "\n",
    "What will we do?\n",
    "* implement main network \n",
    "* drop the t-net mini models as layers in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f788f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "    \n",
    "    def get_config(self): #TODO required for saving model\n",
    "        return {'test': 'test'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnet(inputs, num_features):\n",
    "    '''Build T-net layers'''\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 32) # Original 256 in paper\n",
    "    x = dense_bn(x, 16) # Original 128 in paper\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfdcd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pointnet(num_points, num_classes):\n",
    "    '''Use the functional API to build a PointNet model (different from the Sequential API)'''\n",
    "    inputs = keras.Input(shape=(num_points, 3))\n",
    "\n",
    "    x = tnet(inputs, 3)\n",
    "    x = conv_bn(x, 32)\n",
    "    x = conv_bn(x, 32)\n",
    "    x = tnet(x, 32)\n",
    "    x = conv_bn(x, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17437083",
   "metadata": {},
   "source": [
    "Now we have all utility functions we need for our PointNet model<br>\n",
    "We have to preprocess the input data to be compatible with the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd660fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cv_approach_point_clouds(np_batches:np.array, df:pd.DataFrame, user_list:list, num_user_test:int=2) -> Tuple[np.array, np.array, np.array, np.array, list]:\n",
    "    '''\n",
    "    MODIFIED for point cloud data\n",
    "    each user is iteratively left out from training and used as a test set. \n",
    "    We then tests the generalization of the algorithm to new users. \n",
    "    A 'User' attribute is provided to accomodate this strategy. \n",
    "    '''\n",
    "\n",
    "    def cv_ratio(y_test, df):\n",
    "        print(f'Ratio of test set: {len(y_test)/len(df)}')\n",
    "    \n",
    "    # Get the indices for the training and test set\n",
    "    train_indices, test_indices, user_list = get_train_test_user(df, user_list, num_user_test)\n",
    "    print(f'train_indices examples: {len(train_indices)}')\n",
    "    print(f'test_indices examples: {len(test_indices)}')\n",
    "    # Create the training and test set\n",
    "    # MODIFIED for point cloud data\n",
    "    X_train = np_batches[train_indices, :, :]\n",
    "    y_train = df.iloc[train_indices, :]['Class']\n",
    "    X_test = np_batches[test_indices, :, :]\n",
    "    y_test = df.iloc[test_indices, :]['Class']\n",
    "\n",
    "    cv_ratio(y_test, df)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_pn_model(name, np_batches:np.array, df:pd.DataFrame, hyperparams:dict):\n",
    "    '''\n",
    "    Train multiple PointNet models with k-fold cross validation (leave n users out strategy)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str, Name of the model.\n",
    "    np_batches : numpy.ndarray, The data.\n",
    "    df : pandas.DataFrame, We will use this dataframe ONLY to get the labels.\n",
    "    hyperparams : dict, The hyperparameters.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    best_model : keras.Sequential, The best model.\n",
    "    best_acc : float, The best accuracy.\n",
    "    X_test_best : numpy.ndarray, X_test set\n",
    "    y_test_best : numpy.ndarray, y_test set\n",
    "    '''\n",
    "    \n",
    "\n",
    "    # Create a list of users\n",
    "    user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "    # Number of users to be used for the test set\n",
    "    num_user_test = 2\n",
    "    num_of_iterations = 4\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    X_test_best = None\n",
    "    y_test_best = None\n",
    "\n",
    "    all_acc_val = []\n",
    "    all_prec_val = []\n",
    "\n",
    "    # Evaluation dict\n",
    "    #TODO add recall and f1 score\n",
    "    eval_dict = {'train': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []},\n",
    "                 'test': {'accuracy':[], 'precision':[], 'recall':[], 'f1': []}}\n",
    "\n",
    "    describe_model = True\n",
    "\n",
    "    for i in range(num_of_iterations):\n",
    "\n",
    "        print('*'*50)\n",
    "        print(f'CV Run: {i}')\n",
    "\n",
    "        # Split the data into train and test set\n",
    "        X_train_cv_pn, y_train_cv_pn, X_test_cv_pn, y_test_cv_pn, user_list = custom_cv_approach_point_clouds(np_batches, df_raw, user_list, num_user_test=num_user_test)\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_cv_pn = scaler.fit_transform(X_train_cv_pn.reshape(-1, X_train_cv_pn.shape[-1])).reshape(X_train_cv_pn.shape)\n",
    "        X_test_cv_pn = scaler.transform(X_test_cv_pn.reshape(-1, X_test_cv_pn.shape[-1])).reshape(X_test_cv_pn.shape)\n",
    "        # Before one hot encoding, class has to start at 0\n",
    "        y_train_cv_pn = y_train_cv_pn-1\n",
    "        y_test_cv_pn = y_test_cv_pn-1\n",
    "        # y label to one hot encode\n",
    "        y_train_cv_pn = to_categorical(y_train_cv_pn)\n",
    "        y_test_cv_pn = to_categorical(y_test_cv_pn)\n",
    "\n",
    "        # Build model\n",
    "        print('X_train.shape: ', X_train_cv_pn.shape)\n",
    "        print('Sample input shape: ', X_train_cv_pn[0].shape)\n",
    "        print('Sample input: ', X_train_cv_pn[0])\n",
    "        print('y_train.shape: ', y_train_cv_pn.shape)\n",
    "        \n",
    "        max_num_points = 10\n",
    "        #TODO add hyperparams\n",
    "        pointnet_model = build_pointnet(max_num_points, y_train_cv_pn.shape[1])\n",
    "\n",
    "        # Only print the model summary once\n",
    "        if describe_model:\n",
    "            pointnet_model.summary()\n",
    "            describe_model = False\n",
    "\n",
    "        # Create callback\n",
    "        #early_stop_callback = keras.callbacks.EarlyStopping(monitor=\"val_categorical_accuracy\", min_delta=1e-4, patience=5, verbose=1)\n",
    "        checkpoint_callback = keras.callbacks.ModelCheckpoint(f'model/single_run/{name}_cv{i}.h5', save_best_only=True)\n",
    "        \n",
    "        pointnet_model.compile(\n",
    "            loss=hyperparams['loss'],\n",
    "            optimizer=hyperparams['optimizer'],\n",
    "            metrics=hyperparams['metrics'],\n",
    "            )\n",
    "\n",
    "        # Train the model\n",
    "        history = pointnet_model.fit(X_train_cv_pn, \n",
    "                                y_train_cv_pn, \n",
    "                                epochs=hyperparams['num_epochs'], \n",
    "                                batch_size= hyperparams['batch_size'],\n",
    "                                validation_data=(X_test_cv_pn, y_test_cv_pn),\n",
    "                                verbose=1,\n",
    "                                shuffle=True,\n",
    "                                callbacks=[checkpoint_callback])\n",
    "\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        hist['epoch'] = history.epoch\n",
    "\n",
    "        # Save the history\n",
    "        save_history(hist, f'{name}_cv{i}')\n",
    "\n",
    "        #Evaluating the training performance:\n",
    "        train_loss, train_acc, train_precision, train_recall = pointnet_model.evaluate(x=X_train_cv_pn, y=y_train_cv_pn, batch_size=hyperparams['batch_size'], verbose=1)\n",
    "        f1_score_train = calc_f1_score_mlp(pointnet_model, X_train_cv_pn, y_train_cv_pn)\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'train', train_acc, train_precision, train_recall, f1_score_train)\n",
    "        print('-'*70)\n",
    "        print('Evaluation of training Data: \\n', 'training loss: ', train_loss, 'training accuracy: ', train_acc)\n",
    "\n",
    "        #Evaluating the CV pperformance:\n",
    "        val_loss, val_acc, val_precision, val_recall = pointnet_model.evaluate(x=X_test_cv_pn, y=y_test_cv_pn, batch_size=hyperparams['batch_size'], verbose=1)\n",
    "        f1_score_test = calc_f1_score_mlp(pointnet_model, X_test_cv_pn, y_test_cv_pn)\n",
    "        eval_dict = save_to_eval_dict(eval_dict, 'train', val_acc, val_precision, val_recall, f1_score_test)\n",
    "        all_acc_val.append(val_acc)\n",
    "        all_prec_val.append(val_precision)\n",
    "        print('Evaluation of validation Data: \\n', 'cv loss: ', val_loss, 'cv accuracy: ', val_acc)\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_model = pointnet_model\n",
    "            best_acc = val_acc\n",
    "            X_test_best = X_test_cv_pn\n",
    "            y_test_best = y_test_cv_pn\n",
    "\n",
    "    #Lets see the overall score as average of the scores of all the folds:\n",
    "    print('-'*70)\n",
    "    print('(all CV runs combined)')\n",
    "    print('Mean Accuracy  for the validation dataset: ', np.mean(all_acc_val))\n",
    "    print('Mean Precision for the validation dataset: ', np.mean(all_prec_val))\n",
    "    print('-'*70)\n",
    "\n",
    "    # Save the model\n",
    "    best_model.save(f'model/single_run/{name}_best_model.h5')\n",
    "\n",
    "    # Save the evaluation dict\n",
    "    save_eval_dict_pkl(eval_dict, f'{name}_eval_dict')\n",
    "\n",
    "    # Plot the learning curves\n",
    "    plot_learning_curves(hist, hyperparams, name)\n",
    "\n",
    "    return best_model, best_acc, X_test_best, y_test_best, eval_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row of data (multiple data points) got stored as single dataframe where each row is one single data point\n",
    "# Convert the dataframe to 3D numpy Matrix \n",
    "np_batches = np.array(list(map(pd.DataFrame.to_numpy, concat_batches)))\n",
    "np_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a206d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to reshape the data to be able to normalize it\n",
    "# EXAMPLE: for 2 batches (for the real data we will do it in the training loop)\n",
    "print(np_batches[0:2].shape)\n",
    "reshaped = np_batches[0:2].reshape(-1, np_batches[0].shape[-1])\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "#TODO set number of epochs to 15\n",
    "# TODO have a look what \"sparse_categorical_crossentropy\" is\n",
    "hyperparams = {'num_epochs': 20,\n",
    "               'batch_size':10,\n",
    "               'hidden_layer':2,\n",
    "               'units_hidden_layer': 32,\n",
    "               'activation_hidden': 'relu',\n",
    "               'activation_output': 'softmax',\n",
    "               'loss': 'categorical_crossentropy',\n",
    "               'metrics': ['categorical_accuracy', 'Precision', tf.keras.metrics.Recall()],\n",
    "               'optimizer': keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "               'initialization': '-',\n",
    "               'weight regularisation l2': '-',\n",
    "               'dropout': '-',  # typically between 0.3 and 0.5 (half of weights get 0)\n",
    "               'early Stopping': 'False'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO have a look what is point 0 X0, Y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "name = 'pointnet_base'\n",
    "best_model, best_acc, X_test_best, y_test_best, eval_dict_pn = train_k_pn_model(name, np_batches, df_raw, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_learning_curves(name, {'test': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf15363",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict_pn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d93751-254a-4e14-8206-57c62006cc1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 5. Testing Phase III: Model Regularization and Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1521b643",
   "metadata": {},
   "source": [
    "This section is reserved for neural networks, Fine tune models\n",
    "regularization\n",
    "make notes of the trials\n",
    "save plots\n",
    "use CV to optimize the model\n",
    "Add a brief description of this optimization process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae79e8bc",
   "metadata": {},
   "source": [
    "number of neurons\n",
    "regularization\n",
    "number layers\n",
    "dropout\n",
    "Initialization\n",
    "Optimizer\n",
    "Batch Size\n",
    "Epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7874613",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9928671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "\n",
    "class Classification_MLP_tuner(HyperModel):\n",
    "    '''\n",
    "    Build a HyperParameter Model with variable hyperparameters\n",
    "    e.g. Optimizer, learning rate \n",
    "    \n",
    "    Note: model.compile must be included in this function\n",
    "    '''\n",
    "\n",
    "    def __init__(self, name:str, input_shape, num_output, max_num_of_hidd_layer:int, max_num_of_neuron_per_layer:int, min_num_of_neuron_per_layer:int, activation_func_hidden_layer:list):\n",
    "        self.name = name\n",
    "        self.input_shape = input_shape\n",
    "        self.num_ouput = num_output\n",
    "        self.max_num_of_hidd_layer = max_num_of_hidd_layer\n",
    "        self.max_num_of_neuron_per_layer = max_num_of_neuron_per_layer\n",
    "        self.min_num_of_neuron_per_layer = min_num_of_neuron_per_layer\n",
    "        self.activation_func_hidden_layer = activation_func_hidden_layer\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        model = keras.Sequential(name=self.name)\n",
    "        model.add(layers.InputLayer(input_shape=self.input_shape))\n",
    "        for i in range(hp.Int('num_layers', 1, self.max_num_of_hidd_layer)):\n",
    "            model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                min_value=self.min_num_of_neuron_per_layer,\n",
    "                                                max_value=self.max_num_of_neuron_per_layer,\n",
    "                                                step=2),\n",
    "                                    activation=hp.Choice(\n",
    "                                            'dense_activation',\n",
    "                                            values=self.activation_func_hidden_layer\n",
    "                                            )))\n",
    "        model.add(layers.Dense(5, activation='softmax')) #TODO output variable\n",
    "\n",
    "        #Compile\n",
    "        opt = keras.optimizers.Adam(hp.Float(\n",
    "                                'learning_rate',\n",
    "                                min_value=1e-5,\n",
    "                                max_value=1e-2,\n",
    "                                sampling='LOG',\n",
    "                                default=1e-3)\n",
    "                                )\n",
    "        metrics = [keras.metrics.CategoricalAccuracy()]\n",
    "        loss_func = keras.losses.CategoricalCrossentropy()\n",
    "        model.compile(loss=loss_func, optimizer=opt, metrics=metrics)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacffca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_hyperparameter_search(df, max_trials:int, epochs:int, batch_size:int, load_search:Optional[str]=None):\n",
    "    '''\n",
    "    Suche nach den besten Hyperparametern des MLP\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_trials :\n",
    "        maximum number of random models to investigate\n",
    "    epochs :\n",
    "        number of iterations to train neural network\n",
    "    batch_size :\n",
    "        Anzahl der Samples fuer die Gradient berechnet wird (somit gemittelt)\n",
    "    '''\n",
    "\n",
    "    # Create a list of users\n",
    "    user_list = [0, 1, 2, 5, 6, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "    # Number of users to be used for the test set\n",
    "    num_user_test = 2\n",
    "    num_of_iterations = 4\n",
    "    \n",
    "    #create folder\n",
    "    search_path = join('model/hp_search', 'mlp')\n",
    "\n",
    "    #Convert input data\n",
    "    X_train, y_train, X_test, y_test, user_list = custom_cv_approach(df, user_list, num_user_test=num_user_test)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    # Before one hot encoding, class has to start at 0\n",
    "    y_train = y_train-1\n",
    "    y_test = y_test-1\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    #Transform to Dataset\n",
    "    X_train_stream_labeled = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    X_test_stream_labeled = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    # Shuffle Data\n",
    "    X_train_stream_labeled = X_train_stream_labeled.shuffle(buffer_size=df.shape[0])\n",
    "    X_test_stream_labeled = X_test_stream_labeled.shuffle(buffer_size=df.shape[0])\n",
    "    #create batches\n",
    "    X_train_stream_labeled = X_train_stream_labeled.batch(batch_size)\n",
    "    X_test_stream_labeled = X_test_stream_labeled.batch(batch_size)\n",
    "\n",
    "    #build model\n",
    "    input_shape = (X_train.shape[1], )\n",
    "    output_shape = len(np.unique(y_train))\n",
    "    \n",
    "    #TODO write them in hyper param dict\n",
    "    activation_func_hidden_layer = ['relu']#['tanh', 'sigmoid', 'elu', 'relu']\n",
    "    min_num_of_neuron_per_layer = 4\n",
    "    mlp_model = Classification_MLP_tuner('mlp', input_shape, output_shape, max_num_of_hidd_layer=5, max_num_of_neuron_per_layer=32, min_num_of_neuron_per_layer=min_num_of_neuron_per_layer, activation_func_hidden_layer=activation_func_hidden_layer)\n",
    "\n",
    "    # Create name with timestamp\n",
    "    t = time.localtime()\n",
    "    timestamp = time.strftime('%b-%d-%Y_%H%M', t)\n",
    "\n",
    "    #train\n",
    "    if load_search is None:\n",
    "        tuner_search = keras_tuner.RandomSearch(mlp_model, objective='val_categorical_accuracy', max_trials=max_trials, project_name=join(search_path, f'prj_{timestamp}_mlp'))\n",
    "        tuner_search.search(X_train_stream_labeled, epochs=epochs, validation_data=X_test_stream_labeled)\n",
    "\n",
    "        # Not required anymore, search can be easily restored from search path!\n",
    "        '''\n",
    "        pickle_path = join(search_path, f'mlp_search_{timestamp}.pkl')\n",
    "        with open(pickle_path, 'wb') as handle:\n",
    "            pickle.dump(tuner_search, handle)\n",
    "        '''\n",
    "    else:\n",
    "        tuner_search = keras_tuner.RandomSearch(mlp_model, objective='val_categorical_accuracy', max_trials=max_trials, overwrite=False, project_name=load_search)\n",
    "        return tuner_search\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca0916ce",
   "metadata": {},
   "source": [
    "We perform a random search in hyperparameter space with the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOOD write all hyperparameter options in one dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_hyperparameter_search(df_raw, max_trials=150, epochs=10, batch_size=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "608a2f67",
   "metadata": {},
   "source": [
    "We should always make sure that we can restore or load important evvaluation data, whole models or search results.<br>\n",
    "Coming back after 2 days of random hyperparameter search only to find out that the kernel crashed or restarted at any point in time is suboptimal<br>\n",
    "Simply relying on the fact that the jupyter kernel will store the python objects is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '/home/josh/dde1_hand_motion/model/hp_search/mlp/prj_Mar-09-2023_2332_mlp'\n",
    "tuner_search = mlp_hyperparameter_search(df_raw, max_trials=1, epochs=1, batch_size=10, load_search = project_path)\n",
    "\n",
    "print(tuner_search.get_best_hyperparameters(4))\n",
    "print(tuner_search.results_summary(4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fd33042",
   "metadata": {},
   "source": [
    "Now perform the same search with the extracted data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28618180",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_hyperparameter_search(df_aggregate, max_trials=150, epochs=10, batch_size=10, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "978f7c2b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231639e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_search_info(pkl_path:str, num_of_model:int):\n",
    "\n",
    "    if os.path.getsize(pkl_path) > 0:\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            rand_search = pickle.load(f)\n",
    "    else:\n",
    "        print('File is empty!')\n",
    "        return\n",
    "\n",
    "    print('best parameter:', rand_search.best_params_)\n",
    "    print('best score:', rand_search.best_score_)\n",
    "\n",
    "    search_df = pd.DataFrame(rand_search.cv_results_)\n",
    "    search_df.set_index('rank_test_score', inplace=True)\n",
    "    \n",
    "    for model_rank in range(1, num_of_model+1):\n",
    "        print(f'\\n###{model_rank}_model###')\n",
    "\n",
    "        try:\n",
    "            params_n_model = search_df['params'][model_rank]\n",
    "            score_n_model = search_df['split0_test_score'][model_rank]\n",
    "        except KeyError:\n",
    "            print(f'no model with rank {model_rank} (previous is multiple')\n",
    "            continue\n",
    "        print(params_n_model)\n",
    "        print(score_n_model)\n",
    "    \n",
    "    return rand_search.best_score_, rand_search.best_params_\n",
    "\n",
    "\n",
    "def keras_tuner_search_results(pkl_path:str):\n",
    "    \n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        rand_search = pickle.load(f)\n",
    "\n",
    "    result_summary = rand_search.results_summary()\n",
    "    print(result_summary)\n",
    "    best_model = rand_search.get_best_models(num_models=1)[0]\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96eb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pickle\n",
    "import os\n",
    "search_path = 'model/hp_search/mlp/mlp_search_Mar-09-2023_2332.pkl'\n",
    "keras_tuner_search_results(search_path)\n",
    "rand_search_info(search_path, num_of_model=10)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e3b9440",
   "metadata": {},
   "source": [
    "## PointNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9113c",
   "metadata": {},
   "source": [
    "# 6. Evaluation of the model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a120227c-6716-4d32-9f35-5c66e81b9efd",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  All Models/Overall Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856f41d-c408-4ea5-9a61-5d4b09fe41cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. Lessons Learnt and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60002ae0",
   "metadata": {},
   "source": [
    "tell us what you found and what you learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e21ae-ecd5-407c-9780-ed5ae5fd8371",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "\n",
    "Gradient Descent\n",
    "\n",
    "Random Forests\n",
    "\n",
    "Boosting (LightGBM)\n",
    "https://lightgbm.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a301e0-6c8d-4cbb-a351-3172541c270b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d86898-22d2-41d8-9bfb-424eb0bbffc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f84c7-3d1c-47b1-9cc2-826b82d14bc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be58b0d-4ccb-44b8-b4d4-775cf717f2bc",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "PR Curve\n",
    "ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96099216-ad7d-4b34-95f0-78142fd66381",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81443258-bf9e-4898-a68d-3f2793d3fb51",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6e58a-1ec3-4c67-a9d3-ecb525c9855f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092be0a4-a71d-4c7a-8a63-85877163de51",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c53728-5edd-4dbf-9019-9718a117ff10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a71aa70298631feedc494dbad6cb00b706fca5b11f5a9d39eafcd631df241c69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
